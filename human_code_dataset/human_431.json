{
    "code": "class MarkItDown:\n    \"\"\"(In preview) An extremely simple text-based document reader, suitable for LLM use.\n    This reader will convert common file-types or webpages to Markdown.\"\"\"\n\n    def __init__(\n        self,\n        *,\n        enable_builtins: Union[None, bool] = None,\n        enable_plugins: Union[None, bool] = None,\n        **kwargs,\n    ):\n        self._builtins_enabled = False\n        self._plugins_enabled = False\n\n        requests_session = kwargs.get(\"requests_session\")\n        if requests_session is None:\n            self._requests_session = requests.Session()\n        else:\n            self._requests_session = requests_session\n\n        self._magika = magika.Magika()\n\n        # TODO - remove these (see enable_builtins)\n        self._llm_client: Any = None\n        self._llm_model: Union[str | None] = None\n        self._llm_prompt: Union[str | None] = None\n        self._exiftool_path: Union[str | None] = None\n        self._style_map: Union[str | None] = None\n\n        # Register the converters\n        self._converters: List[ConverterRegistration] = []\n\n        if (\n            enable_builtins is None or enable_builtins\n        ):  # Default to True when not specified\n            self.enable_builtins(**kwargs)\n\n        if enable_plugins:\n            self.enable_plugins(**kwargs)\n\n    def enable_builtins(self, **kwargs) -> None:\n        \"\"\"\n        Enable and register built-in converters.\n        Built-in converters are enabled by default.\n        This method should only be called once, if built-ins were initially disabled.\n        \"\"\"\n        if not self._builtins_enabled:\n            # TODO: Move these into converter constructors\n            self._llm_client = kwargs.get(\"llm_client\")\n            self._llm_model = kwargs.get(\"llm_model\")\n            self._llm_prompt = kwargs.get(\"llm_prompt\")\n            self._exiftool_path = kwargs.get(\"exiftool_path\")\n            self._style_map = kwargs.get(\"style_map\")\n\n            if self._exiftool_path is None:\n                self._exiftool_path = os.getenv(\"EXIFTOOL_PATH\")\n\n            # Still none? Check well-known paths\n            if self._exiftool_path is None:\n                candidate = shutil.which(\"exiftool\")\n                if candidate:\n                    candidate = os.path.abspath(candidate)\n                    if any(\n                        d == os.path.dirname(candidate)\n                        for d in [\n                            \"/usr/bin\",\n                            \"/usr/local/bin\",\n                            \"/opt\",\n                            \"/opt/bin\",\n                            \"/opt/local/bin\",\n                            \"/opt/homebrew/bin\",\n                            \"C:\\\\Windows\\\\System32\",\n                            \"C:\\\\Program Files\",\n                            \"C:\\\\Program Files (x86)\",\n                        ]\n                    ):\n                        self._exiftool_path = candidate\n\n            # Register converters for successful browsing operations\n            # Later registrations are tried first / take higher priority than earlier registrations\n            # To this end, the most specific converters should appear below the most generic converters\n            self.register_converter(\n                PlainTextConverter(), priority=PRIORITY_GENERIC_FILE_FORMAT\n            )\n            self.register_converter(\n                ZipConverter(markitdown=self), priority=PRIORITY_GENERIC_FILE_FORMAT\n            )\n            self.register_converter(\n                HtmlConverter(), priority=PRIORITY_GENERIC_FILE_FORMAT\n            )\n            self.register_converter(RssConverter())\n            self.register_converter(WikipediaConverter())\n            self.register_converter(YouTubeConverter())\n            self.register_converter(BingSerpConverter())\n            self.register_converter(DocxConverter())\n            self.register_converter(XlsxConverter())\n            self.register_converter(XlsConverter())\n            self.register_converter(PptxConverter())\n            self.register_converter(AudioConverter())\n            self.register_converter(ImageConverter())\n            self.register_converter(IpynbConverter())\n            self.register_converter(PdfConverter())\n            self.register_converter(OutlookMsgConverter())\n            self.register_converter(EpubConverter())\n            self.register_converter(CsvConverter())\n\n            # Register Document Intelligence converter at the top of the stack if endpoint is provided\n            docintel_endpoint = kwargs.get(\"docintel_endpoint\")\n            if docintel_endpoint is not None:\n                docintel_args: Dict[str, Any] = {}\n                docintel_args[\"endpoint\"] = docintel_endpoint\n\n                docintel_credential = kwargs.get(\"docintel_credential\")\n                if docintel_credential is not None:\n                    docintel_args[\"credential\"] = docintel_credential\n\n                docintel_types = kwargs.get(\"docintel_file_types\")\n                if docintel_types is not None:\n                    docintel_args[\"file_types\"] = docintel_types\n\n                docintel_version = kwargs.get(\"docintel_api_version\")\n                if docintel_version is not None:\n                    docintel_args[\"api_version\"] = docintel_version\n\n                self.register_converter(\n                    DocumentIntelligenceConverter(**docintel_args),\n                )\n\n            self._builtins_enabled = True\n        else:\n            warn(\"Built-in converters are already enabled.\", RuntimeWarning)\n\n    def enable_plugins(self, **kwargs) -> None:\n        \"\"\"\n        Enable and register converters provided by plugins.\n        Plugins are disabled by default.\n        This method should only be called once, if plugins were initially disabled.\n        \"\"\"\n        if not self._plugins_enabled:\n            # Load plugins\n            plugins = _load_plugins()\n            assert plugins is not None\n            for plugin in plugins:\n                try:\n                    plugin.register_converters(self, **kwargs)\n                except Exception:\n                    tb = traceback.format_exc()\n                    warn(f\"Plugin '{plugin}' failed to register converters:\\n{tb}\")\n            self._plugins_enabled = True\n        else:\n            warn(\"Plugins converters are already enabled.\", RuntimeWarning)\n\n    def convert(\n        self,\n        source: Union[str, requests.Response, Path, BinaryIO],\n        *,\n        stream_info: Optional[StreamInfo] = None,\n        **kwargs: Any,\n    ) -> DocumentConverterResult:  # TODO: deal with kwargs\n        \"\"\"\n        Args:\n            - source: can be a path (str or Path), url, or a requests.response object\n            - stream_info: optional stream info to use for the conversion. If None, infer from source\n            - kwargs: additional arguments to pass to the converter\n        \"\"\"\n\n        # Local path or url\n        if isinstance(source, str):\n            if (\n                source.startswith(\"http:\")\n                or source.startswith(\"https:\")\n                or source.startswith(\"file:\")\n                or source.startswith(\"data:\")\n            ):\n                # Rename the url argument to mock_url\n                # (Deprecated -- use stream_info)\n                _kwargs = {k: v for k, v in kwargs.items()}\n                if \"url\" in _kwargs:\n                    _kwargs[\"mock_url\"] = _kwargs[\"url\"]\n                    del _kwargs[\"url\"]\n\n                return self.convert_uri(source, stream_info=stream_info, **_kwargs)\n            else:\n                return self.convert_local(source, stream_info=stream_info, **kwargs)\n        # Path object\n        elif isinstance(source, Path):\n            return self.convert_local(source, stream_info=stream_info, **kwargs)\n        # Request response\n        elif isinstance(source, requests.Response):\n            return self.convert_response(source, stream_info=stream_info, **kwargs)\n        # Binary stream\n        elif (\n            hasattr(source, \"read\")\n            and callable(source.read)\n            and not isinstance(source, io.TextIOBase)\n        ):\n            return self.convert_stream(source, stream_info=stream_info, **kwargs)\n        else:\n            raise TypeError(\n                f\"Invalid source type: {type(source)}. Expected str, requests.Response, BinaryIO.\"\n            )\n\n    def convert_local(\n        self,\n        path: Union[str, Path],\n        *,\n        stream_info: Optional[StreamInfo] = None,\n        file_extension: Optional[str] = None,  # Deprecated -- use stream_info\n        url: Optional[str] = None,  # Deprecated -- use stream_info\n        **kwargs: Any,\n    ) -> DocumentConverterResult:\n        if isinstance(path, Path):\n            path = str(path)\n\n        # Build a base StreamInfo object from which to start guesses\n        base_guess = StreamInfo(\n            local_path=path,\n            extension=os.path.splitext(path)[1],\n            filename=os.path.basename(path),\n        )\n\n        # Extend the base_guess with any additional info from the arguments\n        if stream_info is not None:\n            base_guess = base_guess.copy_and_update(stream_info)\n\n        if file_extension is not None:\n            # Deprecated -- use stream_info\n            base_guess = base_guess.copy_and_update(extension=file_extension)\n\n        if url is not None:\n            # Deprecated -- use stream_info\n            base_guess = base_guess.copy_and_update(url=url)\n\n        with open(path, \"rb\") as fh:\n            guesses = self._get_stream_info_guesses(\n                file_stream=fh, base_guess=base_guess\n            )\n            return self._convert(file_stream=fh, stream_info_guesses=guesses, **kwargs)\n\n    def convert_stream(\n        self,\n        stream: BinaryIO,\n        *,\n        stream_info: Optional[StreamInfo] = None,\n        file_extension: Optional[str] = None,  # Deprecated -- use stream_info\n        url: Optional[str] = None,  # Deprecated -- use stream_info\n        **kwargs: Any,\n    ) -> DocumentConverterResult:\n        guesses: List[StreamInfo] = []\n\n        # Do we have anything on which to base a guess?\n        base_guess = None\n        if stream_info is not None or file_extension is not None or url is not None:\n            # Start with a non-Null base guess\n            if stream_info is None:\n                base_guess = StreamInfo()\n            else:\n                base_guess = stream_info\n\n            if file_extension is not None:\n                # Deprecated -- use stream_info\n                assert base_guess is not None  # for mypy\n                base_guess = base_guess.copy_and_update(extension=file_extension)\n\n            if url is not None:\n                # Deprecated -- use stream_info\n                assert base_guess is not None  # for mypy\n                base_guess = base_guess.copy_and_update(url=url)\n\n        # Check if we have a seekable stream. If not, load the entire stream into memory.\n        if not stream.seekable():\n            buffer = io.BytesIO()\n            while True:\n                chunk = stream.read(4096)\n                if not chunk:\n                    break\n                buffer.write(chunk)\n            buffer.seek(0)\n            stream = buffer\n\n        # Add guesses based on stream content\n        guesses = self._get_stream_info_guesses(\n            file_stream=stream, base_guess=base_guess or StreamInfo()\n        )\n        return self._convert(file_stream=stream, stream_info_guesses=guesses, **kwargs)\n\n    def convert_url(\n        self,\n        url: str,\n        *,\n        stream_info: Optional[StreamInfo] = None,\n        file_extension: Optional[str] = None,\n        mock_url: Optional[str] = None,\n        **kwargs: Any,\n    ) -> DocumentConverterResult:\n        \"\"\"Alias for convert_uri()\"\"\"\n        # convert_url will likely be deprecated in the future in favor of convert_uri\n        return self.convert_uri(\n            url,\n            stream_info=stream_info,\n            file_extension=file_extension,\n            mock_url=mock_url,\n            **kwargs,\n        )\n\n    def convert_uri(\n        self,\n        uri: str,\n        *,\n        stream_info: Optional[StreamInfo] = None,\n        file_extension: Optional[str] = None,  # Deprecated -- use stream_info\n        mock_url: Optional[\n            str\n        ] = None,  # Mock the request as if it came from a different URL\n        **kwargs: Any,\n    ) -> DocumentConverterResult:\n        uri = uri.strip()\n\n        # File URIs\n        if uri.startswith(\"file:\"):\n            netloc, path = file_uri_to_path(uri)\n            if netloc and netloc != \"localhost\":\n                raise ValueError(\n                    f\"Unsupported file URI: {uri}. Netloc must be empty or localhost.\"\n                )\n            return self.convert_local(\n                path,\n                stream_info=stream_info,\n                file_extension=file_extension,\n                url=mock_url,\n                **kwargs,\n            )\n        # Data URIs\n        elif uri.startswith(\"data:\"):\n            mimetype, attributes, data = parse_data_uri(uri)\n\n            base_guess = StreamInfo(\n                mimetype=mimetype,\n                charset=attributes.get(\"charset\"),\n            )\n            if stream_info is not None:\n                base_guess = base_guess.copy_and_update(stream_info)\n\n            return self.convert_stream(\n                io.BytesIO(data),\n                stream_info=base_guess,\n                file_extension=file_extension,\n                url=mock_url,\n                **kwargs,\n            )\n        # HTTP/HTTPS URIs\n        elif uri.startswith(\"http:\") or uri.startswith(\"https:\"):\n            response = self._requests_session.get(uri, stream=True)\n            response.raise_for_status()\n            return self.convert_response(\n                response,\n                stream_info=stream_info,\n                file_extension=file_extension,\n                url=mock_url,\n                **kwargs,\n            )\n        else:\n            raise ValueError(\n                f\"Unsupported URI scheme: {uri.split(':')[0]}. Supported schemes are: file:, data:, http:, https:\"\n            )\n\n    def convert_response(\n        self,\n        response: requests.Response,\n        *,\n        stream_info: Optional[StreamInfo] = None,\n        file_extension: Optional[str] = None,  # Deprecated -- use stream_info\n        url: Optional[str] = None,  # Deprecated -- use stream_info\n        **kwargs: Any,\n    ) -> DocumentConverterResult:\n        # If there is a content-type header, get the mimetype and charset (if present)\n        mimetype: Optional[str] = None\n        charset: Optional[str] = None\n\n        if \"content-type\" in response.headers:\n            parts = response.headers[\"content-type\"].split(\";\")\n            mimetype = parts.pop(0).strip()\n            for part in parts:\n                if part.strip().startswith(\"charset=\"):\n                    _charset = part.split(\"=\")[1].strip()\n                    if len(_charset) > 0:\n                        charset = _charset\n\n        # If there is a content-disposition header, get the filename and possibly the extension\n        filename: Optional[str] = None\n        extension: Optional[str] = None\n        if \"content-disposition\" in response.headers:\n            m = re.search(r\"filename=([^;]+)\", response.headers[\"content-disposition\"])\n            if m:\n                filename = m.group(1).strip(\"\\\"'\")\n                _, _extension = os.path.splitext(filename)\n                if len(_extension) > 0:\n                    extension = _extension\n\n        # If there is still no filename, try to read it from the url\n        if filename is None:\n            parsed_url = urlparse(response.url)\n            _, _extension = os.path.splitext(parsed_url.path)\n            if len(_extension) > 0:  # Looks like this might be a file!\n                filename = os.path.basename(parsed_url.path)\n                extension = _extension\n\n        # Create an initial guess from all this information\n        base_guess = StreamInfo(\n            mimetype=mimetype,\n            charset=charset,\n            filename=filename,\n            extension=extension,\n            url=response.url,\n        )\n\n        # Update with any additional info from the arguments\n        if stream_info is not None:\n            base_guess = base_guess.copy_and_update(stream_info)\n        if file_extension is not None:\n            # Deprecated -- use stream_info\n            base_guess = base_guess.copy_and_update(extension=file_extension)\n        if url is not None:\n            # Deprecated -- use stream_info\n            base_guess = base_guess.copy_and_update(url=url)\n\n        # Read into BytesIO\n        buffer = io.BytesIO()\n        for chunk in response.iter_content(chunk_size=512):\n            buffer.write(chunk)\n        buffer.seek(0)\n\n        # Convert\n        guesses = self._get_stream_info_guesses(\n            file_stream=buffer, base_guess=base_guess\n        )\n        return self._convert(file_stream=buffer, stream_info_guesses=guesses, **kwargs)\n\n    def _convert(\n        self, *, file_stream: BinaryIO, stream_info_guesses: List[StreamInfo], **kwargs\n    ) -> DocumentConverterResult:\n        res: Union[None, DocumentConverterResult] = None\n\n        # Keep track of which converters throw exceptions\n        failed_attempts: List[FailedConversionAttempt] = []\n\n        # Create a copy of the page_converters list, sorted by priority.\n        # We do this with each call to _convert because the priority of converters may change between calls.\n        # The sort is guaranteed to be stable, so converters with the same priority will remain in the same order.\n        sorted_registrations = sorted(self._converters, key=lambda x: x.priority)\n\n        # Remember the initial stream position so that we can return to it\n        cur_pos = file_stream.tell()\n\n        for stream_info in stream_info_guesses + [StreamInfo()]:\n            for converter_registration in sorted_registrations:\n                converter = converter_registration.converter\n                # Sanity check -- make sure the cur_pos is still the same\n                assert (\n                    cur_pos == file_stream.tell()\n                ), \"File stream position should NOT change between guess iterations\"\n\n                _kwargs = {k: v for k, v in kwargs.items()}\n\n                # Copy any additional global options\n                if \"llm_client\" not in _kwargs and self._llm_client is not None:\n                    _kwargs[\"llm_client\"] = self._llm_client\n\n                if \"llm_model\" not in _kwargs and self._llm_model is not None:\n                    _kwargs[\"llm_model\"] = self._llm_model\n\n                if \"llm_prompt\" not in _kwargs and self._llm_prompt is not None:\n                    _kwargs[\"llm_prompt\"] = self._llm_prompt\n\n                if \"style_map\" not in _kwargs and self._style_map is not None:\n                    _kwargs[\"style_map\"] = self._style_map\n\n                if \"exiftool_path\" not in _kwargs and self._exiftool_path is not None:\n                    _kwargs[\"exiftool_path\"] = self._exiftool_path\n\n                # Add the list of converters for nested processing\n                _kwargs[\"_parent_converters\"] = self._converters\n\n                # Add legaxy kwargs\n                if stream_info is not None:\n                    if stream_info.extension is not None:\n                        _kwargs[\"file_extension\"] = stream_info.extension\n\n                    if stream_info.url is not None:\n                        _kwargs[\"url\"] = stream_info.url\n\n                # Check if the converter will accept the file, and if so, try to convert it\n                _accepts = False\n                try:\n                    _accepts = converter.accepts(file_stream, stream_info, **_kwargs)\n                except NotImplementedError:\n                    pass\n\n                # accept() should not have changed the file stream position\n                assert (\n                    cur_pos == file_stream.tell()\n                ), f\"{type(converter).__name__}.accept() should NOT change the file_stream position\"\n\n                # Attempt the conversion\n                if _accepts:\n                    try:\n                        res = converter.convert(file_stream, stream_info, **_kwargs)\n                    except Exception:\n                        failed_attempts.append(\n                            FailedConversionAttempt(\n                                converter=converter, exc_info=sys.exc_info()\n                            )\n                        )\n                    finally:\n                        file_stream.seek(cur_pos)\n\n                if res is not None:\n                    # Normalize the content\n                    res.text_content = \"\\n\".join(\n                        [line.rstrip() for line in re.split(r\"\\r?\\n\", res.text_content)]\n                    )\n                    res.text_content = re.sub(r\"\\n{3,}\", \"\\n\\n\", res.text_content)\n                    return res\n\n        # If we got this far without success, report any exceptions\n        if len(failed_attempts) > 0:\n            raise FileConversionException(attempts=failed_attempts)\n\n        # Nothing can handle it!\n        raise UnsupportedFormatException(\n            \"Could not convert stream to Markdown. No converter attempted a conversion, suggesting that the filetype is simply not supported.\"\n        )\n\n    def register_page_converter(self, converter: DocumentConverter) -> None:\n        \"\"\"DEPRECATED: User register_converter instead.\"\"\"\n        warn(\n            \"register_page_converter is deprecated. Use register_converter instead.\",\n            DeprecationWarning,\n        )\n        self.register_converter(converter)\n\n    def register_converter(\n        self,\n        converter: DocumentConverter,\n        *,\n        priority: float = PRIORITY_SPECIFIC_FILE_FORMAT,\n    ) -> None:\n        \"\"\"\n        Register a DocumentConverter with a given priority.\n\n        Priorities work as follows: By default, most converters get priority\n        DocumentConverter.PRIORITY_SPECIFIC_FILE_FORMAT (== 0). The exception\n        is the PlainTextConverter, HtmlConverter, and ZipConverter, which get\n        priority PRIORITY_SPECIFIC_FILE_FORMAT (== 10), with lower values\n        being tried first (i.e., higher priority).\n\n        Just prior to conversion, the converters are sorted by priority, using\n        a stable sort. This means that converters with the same priority will\n        remain in the same order, with the most recently registered converters\n        appearing first.\n\n        We have tight control over the order of built-in converters, but\n        plugins can register converters in any order. The registration's priority\n        field reasserts some control over the order of converters.\n\n        Plugins can register converters with any priority, to appear before or\n        after the built-ins. For example, a plugin with priority 9 will run\n        before the PlainTextConverter, but after the built-in converters.\n        \"\"\"\n        self._converters.insert(\n            0, ConverterRegistration(converter=converter, priority=priority)\n        )\n\n    def _get_stream_info_guesses(\n        self, file_stream: BinaryIO, base_guess: StreamInfo\n    ) -> List[StreamInfo]:\n        \"\"\"\n        Given a base guess, attempt to guess or expand on the stream info using the stream content (via magika).\n        \"\"\"\n        guesses: List[StreamInfo] = []\n\n        # Enhance the base guess with information based on the extension or mimetype\n        enhanced_guess = base_guess.copy_and_update()\n\n        # If there's an extension and no mimetype, try to guess the mimetype\n        if base_guess.mimetype is None and base_guess.extension is not None:\n            _m, _ = mimetypes.guess_type(\n                \"placeholder\" + base_guess.extension, strict=False\n            )\n            if _m is not None:\n                enhanced_guess = enhanced_guess.copy_and_update(mimetype=_m)\n\n        # If there's a mimetype and no extension, try to guess the extension\n        if base_guess.mimetype is not None and base_guess.extension is None:\n            _e = mimetypes.guess_all_extensions(base_guess.mimetype, strict=False)\n            if len(_e) > 0:\n                enhanced_guess = enhanced_guess.copy_and_update(extension=_e[0])\n\n        # Call magika to guess from the stream\n        cur_pos = file_stream.tell()\n        try:\n            result = self._magika.identify_stream(file_stream)\n            if result.status == \"ok\" and result.prediction.output.label != \"unknown\":\n                # If it's text, also guess the charset\n                charset = None\n                if result.prediction.output.is_text:\n                    # Read the first 4k to guess the charset\n                    file_stream.seek(cur_pos)\n                    stream_page = file_stream.read(4096)\n                    charset_result = charset_normalizer.from_bytes(stream_page).best()\n\n                    if charset_result is not None:\n                        charset = self._normalize_charset(charset_result.encoding)\n\n                # Normalize the first extension listed\n                guessed_extension = None\n                if len(result.prediction.output.extensions) > 0:\n                    guessed_extension = \".\" + result.prediction.output.extensions[0]\n\n                # Determine if the guess is compatible with the base guess\n                compatible = True\n                if (\n                    base_guess.mimetype is not None\n                    and base_guess.mimetype != result.prediction.output.mime_type\n                ):\n                    compatible = False\n\n                if (\n                    base_guess.extension is not None\n                    and base_guess.extension.lstrip(\".\")\n                    not in result.prediction.output.extensions\n                ):\n                    compatible = False\n\n                if (\n                    base_guess.charset is not None\n                    and self._normalize_charset(base_guess.charset) != charset\n                ):\n                    compatible = False\n\n                if compatible:\n                    # Add the compatible base guess\n                    guesses.append(\n                        StreamInfo(\n                            mimetype=base_guess.mimetype\n                            or result.prediction.output.mime_type,\n                            extension=base_guess.extension or guessed_extension,\n                            charset=base_guess.charset or charset,\n                            filename=base_guess.filename,\n                            local_path=base_guess.local_path,\n                            url=base_guess.url,\n                        )\n                    )\n                else:\n                    # The magika guess was incompatible with the base guess, so add both guesses\n                    guesses.append(enhanced_guess)\n                    guesses.append(\n                        StreamInfo(\n                            mimetype=result.prediction.output.mime_type,\n                            extension=guessed_extension,\n                            charset=charset,\n                            filename=base_guess.filename,\n                            local_path=base_guess.local_path,\n                            url=base_guess.url,\n                        )\n                    )\n            else:\n                # There were no other guesses, so just add the base guess\n                guesses.append(enhanced_guess)\n        finally:\n            file_stream.seek(cur_pos)\n\n        return guesses\n\n    def _normalize_charset(self, charset: str | None) -> str | None:\n        \"\"\"\n        Normalize a charset string to a canonical form.\n        \"\"\"\n        if charset is None:\n            return None\n        try:\n            return codecs.lookup(charset).name\n        except LookupError:\n            return charset",
    "source": "github_repo:microsoft/markitdown",
    "file": "packages/markitdown/src/markitdown/_markitdown.py",
    "license": "MIT",
    "language": "python"
}