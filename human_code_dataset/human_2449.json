{
    "code": "def benchmark_speed_cli(\n    # fmt: off\n    ctx: typer.Context,\n    model: str = Arg(..., help=\"Model name or path\"),\n    data_path: Path = Arg(..., help=\"Location of binary evaluation data in .spacy format\", exists=True),\n    batch_size: Optional[int] = Opt(None, \"--batch-size\", \"-b\", min=1, help=\"Override the pipeline batch size\"),\n    no_shuffle: bool = Opt(False, \"--no-shuffle\", help=\"Do not shuffle benchmark data\"),\n    use_gpu: int = Opt(-1, \"--gpu-id\", \"-g\", help=\"GPU ID or -1 for CPU\"),\n    n_batches: int = Opt(50, \"--batches\", help=\"Minimum number of batches to benchmark\", min=30,),\n    warmup_epochs: int = Opt(3, \"--warmup\", \"-w\", min=0, help=\"Number of iterations over the data for warmup\"),\n    code_path: Optional[Path] = Opt(None, \"--code\", \"-c\", help=\"Path to Python file with additional code (registered functions) to be imported\"),\n    # fmt: on\n):\n    \"\"\"\n    Benchmark a pipeline. Expects a loadable spaCy pipeline and benchmark\n    data in the binary .spacy format.\n    \"\"\"\n    import_code(code_path)\n    setup_gpu(use_gpu=use_gpu, silent=False)\n\n    nlp = util.load_model(model)\n    batch_size = batch_size if batch_size is not None else nlp.batch_size\n    corpus = Corpus(data_path)\n    docs = [eg.predicted for eg in corpus(nlp)]\n\n    if len(docs) == 0:\n        msg.fail(\"Cannot benchmark speed using an empty corpus.\", exits=1)\n\n    print(f\"Warming up for {warmup_epochs} epochs...\")\n    warmup(nlp, docs, warmup_epochs, batch_size)\n\n    print()\n    print(f\"Benchmarking {n_batches} batches...\")\n    wps = benchmark(nlp, docs, n_batches, batch_size, not no_shuffle)\n\n    print()\n    print_outliers(wps)\n    print_mean_with_ci(wps)",
    "source": "github_repo:explosion/spaCy",
    "file": "spacy/cli/benchmark_speed.py",
    "license": "MIT",
    "language": "python"
}