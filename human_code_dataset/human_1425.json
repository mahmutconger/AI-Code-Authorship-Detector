{
    "code": "class LatentUpscaleFinetuneDiffusion(LatentFinetuneDiffusion):\n    \"\"\"\n        condition on low-res image (and optionally on some spatial noise augmentation)\n    \"\"\"\n    def __init__(self, concat_keys=(\"lr\",), reshuffle_patch_size=None,\n                 low_scale_config=None, low_scale_key=None, *args, **kwargs):\n        super().__init__(concat_keys=concat_keys, *args, **kwargs)\n        self.reshuffle_patch_size = reshuffle_patch_size\n        self.low_scale_model = None\n        if low_scale_config is not None:\n            print(\"Initializing a low-scale model\")\n            assert exists(low_scale_key)\n            self.instantiate_low_stage(low_scale_config)\n            self.low_scale_key = low_scale_key\n\n    def instantiate_low_stage(self, config):\n        model = instantiate_from_config(config)\n        self.low_scale_model = model.eval()\n        self.low_scale_model.train = disabled_train\n        for param in self.low_scale_model.parameters():\n            param.requires_grad = False\n\n    @torch.no_grad()\n    def get_input(self, batch, k, cond_key=None, bs=None, return_first_stage_outputs=False):\n        # note: restricted to non-trainable encoders currently\n        assert not self.cond_stage_trainable, 'trainable cond stages not yet supported for upscaling-ft'\n        z, c, x, xrec, xc = super().get_input(batch, self.first_stage_key, return_first_stage_outputs=True,\n                                              force_c_encode=True, return_original_cond=True, bs=bs)\n\n        assert exists(self.concat_keys)\n        assert len(self.concat_keys) == 1\n        # optionally make spatial noise_level here\n        c_cat = list()\n        noise_level = None\n        for ck in self.concat_keys:\n            cc = batch[ck]\n            cc = rearrange(cc, 'b h w c -> b c h w')\n            if exists(self.reshuffle_patch_size):\n                assert isinstance(self.reshuffle_patch_size, int)\n                cc = rearrange(cc, 'b c (p1 h) (p2 w) -> b (p1 p2 c) h w',\n                               p1=self.reshuffle_patch_size, p2=self.reshuffle_patch_size)\n            if bs is not None:\n                cc = cc[:bs]\n                cc = cc.to(self.device)\n            if exists(self.low_scale_model) and ck == self.low_scale_key:\n                cc, noise_level = self.low_scale_model(cc)\n            c_cat.append(cc)\n        c_cat = torch.cat(c_cat, dim=1)\n        if exists(noise_level):\n            all_conds = {\"c_concat\": [c_cat], \"c_crossattn\": [c], \"c_adm\": noise_level}\n        else:\n            all_conds = {\"c_concat\": [c_cat], \"c_crossattn\": [c]}\n        if return_first_stage_outputs:\n            return z, all_conds, x, xrec, xc\n        return z, all_conds\n\n    @torch.no_grad()\n    def log_images(self, *args, **kwargs):\n        log = super().log_images(*args, **kwargs)\n        log[\"lr\"] = rearrange(args[0][\"lr\"], 'b h w c -> b c h w')\n        return log",
    "source": "github_repo:Stability-AI/stablediffusion",
    "file": "ldm/models/diffusion/ddpm.py",
    "license": "MIT",
    "language": "python"
}