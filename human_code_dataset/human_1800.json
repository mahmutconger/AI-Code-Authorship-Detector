{
    "code": "def __init__(self):\n        super().__init__()\n        # set the default api_key\n        openai.api_key = conf().get(\"open_ai_api_key\")\n        if conf().get(\"open_ai_api_base\"):\n            openai.api_base = conf().get(\"open_ai_api_base\")\n        proxy = conf().get(\"proxy\")\n        if proxy:\n            openai.proxy = proxy\n        if conf().get(\"rate_limit_chatgpt\"):\n            self.tb4chatgpt = TokenBucket(conf().get(\"rate_limit_chatgpt\", 20))\n        conf_model = conf().get(\"model\") or \"gpt-3.5-turbo\"\n        self.sessions = SessionManager(ChatGPTSession, model=conf().get(\"model\") or \"gpt-3.5-turbo\")\n        # o1相关模型不支持system prompt，暂时用文心模型的session\n\n        self.args = {\n            \"model\": conf_model,  # 对话模型的名称\n            \"temperature\": conf().get(\"temperature\", 0.9),  # 值在[0,1]之间，越大表示回复越具有不确定性\n            # \"max_tokens\":4096,  # 回复最大的字符数\n            \"top_p\": conf().get(\"top_p\", 1),\n            \"frequency_penalty\": conf().get(\"frequency_penalty\", 0.0),  # [-2,2]之间，该值越大则更倾向于产生不同的内容\n            \"presence_penalty\": conf().get(\"presence_penalty\", 0.0),  # [-2,2]之间，该值越大则更倾向于产生不同的内容\n            \"request_timeout\": conf().get(\"request_timeout\", None),  # 请求超时时间，openai接口默认设置为600，对于难问题一般需要较长时间\n            \"timeout\": conf().get(\"request_timeout\", None),  # 重试超时时间，在这个时间内，将会自动重试\n        }\n        # 部分模型暂不支持一些参数，特殊处理\n        if conf_model in [const.O1, const.O1_MINI, const.GPT_5, const.GPT_5_MINI, const.GPT_5_NANO]:\n            remove_keys = [\"temperature\", \"top_p\", \"frequency_penalty\", \"presence_penalty\"]\n            for key in remove_keys:\n                self.args.pop(key, None)  # 如果键不存在，使用 None 来避免抛出错、\n            if conf_model in [const.O1, const.O1_MINI]:  # o1系列模型不支持系统提示词，使用文心模型的session\n                self.sessions = SessionManager(BaiduWenxinSession, model=conf().get(\"model\") or const.O1_MINI)",
    "source": "github_repo:zhayujie/chatgpt-on-wechat",
    "file": "bot/chatgpt/chat_gpt_bot.py",
    "license": "MIT",
    "language": "python"
}