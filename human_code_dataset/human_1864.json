{
    "code": "def sample_next_token(logits, rng, temperature=1.0, top_k=None):\n    \"\"\"Sample a single next token from given logits of shape (B, vocab_size). Returns (B, 1).\"\"\"\n    assert temperature >= 0.0, \"temperature must be non-negative\"\n    if temperature == 0.0:\n        return torch.argmax(logits, dim=-1, keepdim=True)\n    if top_k is not None:\n        k = min(top_k, logits.size(-1))\n        vals, idx = torch.topk(logits, k, dim=-1)\n        vals = vals / temperature\n        probs = F.softmax(vals, dim=-1)\n        choice = torch.multinomial(probs, num_samples=1, generator=rng)\n        return idx.gather(1, choice)\n    else:\n        logits = logits / temperature\n        probs = F.softmax(logits, dim=-1)\n        return torch.multinomial(probs, num_samples=1, generator=rng)",
    "source": "github_repo:karpathy/nanochat",
    "file": "nanochat/engine.py",
    "license": "MIT",
    "language": "python"
}