{
    "code": "class ChatGPTBot(Bot, OpenAIImage):\n    def __init__(self):\n        super().__init__()\n        # set the default api_key\n        openai.api_key = conf().get(\"open_ai_api_key\")\n        if conf().get(\"open_ai_api_base\"):\n            openai.api_base = conf().get(\"open_ai_api_base\")\n        proxy = conf().get(\"proxy\")\n        if proxy:\n            openai.proxy = proxy\n        if conf().get(\"rate_limit_chatgpt\"):\n            self.tb4chatgpt = TokenBucket(conf().get(\"rate_limit_chatgpt\", 20))\n        conf_model = conf().get(\"model\") or \"gpt-3.5-turbo\"\n        self.sessions = SessionManager(ChatGPTSession, model=conf().get(\"model\") or \"gpt-3.5-turbo\")\n        # o1相关模型不支持system prompt，暂时用文心模型的session\n\n        self.args = {\n            \"model\": conf_model,  # 对话模型的名称\n            \"temperature\": conf().get(\"temperature\", 0.9),  # 值在[0,1]之间，越大表示回复越具有不确定性\n            # \"max_tokens\":4096,  # 回复最大的字符数\n            \"top_p\": conf().get(\"top_p\", 1),\n            \"frequency_penalty\": conf().get(\"frequency_penalty\", 0.0),  # [-2,2]之间，该值越大则更倾向于产生不同的内容\n            \"presence_penalty\": conf().get(\"presence_penalty\", 0.0),  # [-2,2]之间，该值越大则更倾向于产生不同的内容\n            \"request_timeout\": conf().get(\"request_timeout\", None),  # 请求超时时间，openai接口默认设置为600，对于难问题一般需要较长时间\n            \"timeout\": conf().get(\"request_timeout\", None),  # 重试超时时间，在这个时间内，将会自动重试\n        }\n        # 部分模型暂不支持一些参数，特殊处理\n        if conf_model in [const.O1, const.O1_MINI, const.GPT_5, const.GPT_5_MINI, const.GPT_5_NANO]:\n            remove_keys = [\"temperature\", \"top_p\", \"frequency_penalty\", \"presence_penalty\"]\n            for key in remove_keys:\n                self.args.pop(key, None)  # 如果键不存在，使用 None 来避免抛出错、\n            if conf_model in [const.O1, const.O1_MINI]:  # o1系列模型不支持系统提示词，使用文心模型的session\n                self.sessions = SessionManager(BaiduWenxinSession, model=conf().get(\"model\") or const.O1_MINI)\n\n    def reply(self, query, context=None):\n        # acquire reply content\n        if context.type == ContextType.TEXT:\n            logger.info(\"[CHATGPT] query={}\".format(query))\n\n            session_id = context[\"session_id\"]\n            reply = None\n            clear_memory_commands = conf().get(\"clear_memory_commands\", [\"#清除记忆\"])\n            if query in clear_memory_commands:\n                self.sessions.clear_session(session_id)\n                reply = Reply(ReplyType.INFO, \"记忆已清除\")\n            elif query == \"#清除所有\":\n                self.sessions.clear_all_session()\n                reply = Reply(ReplyType.INFO, \"所有人记忆已清除\")\n            elif query == \"#更新配置\":\n                load_config()\n                reply = Reply(ReplyType.INFO, \"配置已更新\")\n            if reply:\n                return reply\n            session = self.sessions.session_query(query, session_id)\n            logger.debug(\"[CHATGPT] session query={}\".format(session.messages))\n\n            api_key = context.get(\"openai_api_key\")\n            model = context.get(\"gpt_model\")\n            new_args = None\n            if model:\n                new_args = self.args.copy()\n                new_args[\"model\"] = model\n            # if context.get('stream'):\n            #     # reply in stream\n            #     return self.reply_text_stream(query, new_query, session_id)\n\n            reply_content = self.reply_text(session, api_key, args=new_args)\n            logger.debug(\n                \"[CHATGPT] new_query={}, session_id={}, reply_cont={}, completion_tokens={}\".format(\n                    session.messages,\n                    session_id,\n                    reply_content[\"content\"],\n                    reply_content[\"completion_tokens\"],\n                )\n            )\n            if reply_content[\"completion_tokens\"] == 0 and len(reply_content[\"content\"]) > 0:\n                reply = Reply(ReplyType.ERROR, reply_content[\"content\"])\n            elif reply_content[\"completion_tokens\"] > 0:\n                self.sessions.session_reply(reply_content[\"content\"], session_id, reply_content[\"total_tokens\"])\n                reply = Reply(ReplyType.TEXT, reply_content[\"content\"])\n            else:\n                reply = Reply(ReplyType.ERROR, reply_content[\"content\"])\n                logger.debug(\"[CHATGPT] reply {} used 0 tokens.\".format(reply_content))\n            return reply\n\n        elif context.type == ContextType.IMAGE_CREATE:\n            ok, retstring = self.create_img(query, 0)\n            reply = None\n            if ok:\n                reply = Reply(ReplyType.IMAGE_URL, retstring)\n            else:\n                reply = Reply(ReplyType.ERROR, retstring)\n            return reply\n        else:\n            reply = Reply(ReplyType.ERROR, \"Bot不支持处理{}类型的消息\".format(context.type))\n            return reply\n\n    def reply_text(self, session: ChatGPTSession, api_key=None, args=None, retry_count=0) -> dict:\n        \"\"\"\n        call openai's ChatCompletion to get the answer\n        :param session: a conversation session\n        :param session_id: session id\n        :param retry_count: retry count\n        :return: {}\n        \"\"\"\n        try:\n            if conf().get(\"rate_limit_chatgpt\") and not self.tb4chatgpt.get_token():\n                raise openai.error.RateLimitError(\"RateLimitError: rate limit exceeded\")\n            # if api_key == None, the default openai.api_key will be used\n            if args is None:\n                args = self.args\n            response = openai.ChatCompletion.create(api_key=api_key, messages=session.messages, **args)\n            # logger.debug(\"[CHATGPT] response={}\".format(response))\n            logger.info(\"[ChatGPT] reply={}, total_tokens={}\".format(response.choices[0]['message']['content'], response[\"usage\"][\"total_tokens\"]))\n            return {\n                \"total_tokens\": response[\"usage\"][\"total_tokens\"],\n                \"completion_tokens\": response[\"usage\"][\"completion_tokens\"],\n                \"content\": response.choices[0][\"message\"][\"content\"],\n            }\n        except Exception as e:\n            need_retry = retry_count < 2\n            result = {\"completion_tokens\": 0, \"content\": \"我现在有点累了，等会再来吧\"}\n            if isinstance(e, openai.error.RateLimitError):\n                logger.warn(\"[CHATGPT] RateLimitError: {}\".format(e))\n                result[\"content\"] = \"提问太快啦，请休息一下再问我吧\"\n                if need_retry:\n                    time.sleep(20)\n            elif isinstance(e, openai.error.Timeout):\n                logger.warn(\"[CHATGPT] Timeout: {}\".format(e))\n                result[\"content\"] = \"我没有收到你的消息\"\n                if need_retry:\n                    time.sleep(5)\n            elif isinstance(e, openai.error.APIError):\n                logger.warn(\"[CHATGPT] Bad Gateway: {}\".format(e))\n                result[\"content\"] = \"请再问我一次\"\n                if need_retry:\n                    time.sleep(10)\n            elif isinstance(e, openai.error.APIConnectionError):\n                logger.warn(\"[CHATGPT] APIConnectionError: {}\".format(e))\n                result[\"content\"] = \"我连接不到你的网络\"\n                if need_retry:\n                    time.sleep(5)\n            else:\n                logger.exception(\"[CHATGPT] Exception: {}\".format(e))\n                need_retry = False\n                self.sessions.clear_session(session.session_id)\n\n            if need_retry:\n                logger.warn(\"[CHATGPT] 第{}次重试\".format(retry_count + 1))\n                return self.reply_text(session, api_key, args, retry_count + 1)\n            else:\n                return result",
    "source": "github_repo:zhayujie/chatgpt-on-wechat",
    "file": "bot/chatgpt/chat_gpt_bot.py",
    "license": "MIT",
    "language": "python"
}