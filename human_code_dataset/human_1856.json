{
    "code": "def document_batches():\n        parquet_paths = list_parquet_files()\n        parquet_paths = parquet_paths[:-1] if split == \"train\" else parquet_paths[-1:]\n        resume_pq_idx = resume_state_dict[\"pq_idx\"] if resume_state_dict is not None else 0\n        resume_rg_idx = resume_state_dict[\"rg_idx\"] if resume_state_dict is not None else None\n        pq_idx = resume_pq_idx # we kick off parquet files at the resume index (or by default just 0)\n        while True: # iterate infinitely (multi-epoch)\n            while pq_idx < len(parquet_paths): # iterate over all parquet files\n                filepath = parquet_paths[pq_idx]\n                pf = pq.ParquetFile(filepath)\n                # Start from resume point if resuming on same file, otherwise from DDP rank\n                # I know this state resumption is a little bit tricky and a little bit hacky... sigh.\n                if resume_rg_idx is not None:\n                    base_idx = resume_rg_idx // ddp_world_size # in units of ddp_world_size\n                    base_idx += 1 # advance by 1 so that we definitely don't repeat data after resuming\n                    rg_idx = base_idx * ddp_world_size + ddp_rank\n                    resume_rg_idx = None # set to None as we only want to do this a single time\n                else:\n                    rg_idx = ddp_rank\n                while rg_idx < pf.num_row_groups:\n                    rg = pf.read_row_group(rg_idx)\n                    batch = rg.column('text').to_pylist() # each batch is a parquet group, e.g. 1024 rows\n                    # the tokenizer encode might want to go in even smaller batches, e.g. 128 rows\n                    for i in range(0, len(batch), tokenizer_batch_size):\n                        yield batch[i:i+tokenizer_batch_size], (pq_idx, rg_idx)\n                    rg_idx += ddp_world_size # advance to the next row group (in DDP)\n                pq_idx += 1 # advance to the next parquet file",
    "source": "github_repo:karpathy/nanochat",
    "file": "nanochat/dataloader.py",
    "license": "MIT",
    "language": "python"
}