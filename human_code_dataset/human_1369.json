{
    "code": "def update_readme_stats(stats):\n    \"\"\"Update README.md with current statistics.\"\"\"\n    readme_path = \"README.md\"\n\n    if not os.path.exists(readme_path):\n        print(\"README.md not found\")\n        return False\n\n    with open(readme_path, 'r', encoding='utf-8') as f:\n        content = f.read()\n\n    # Define replacement patterns and their new values\n    replacements = [\n        # Main collection description\n        (r'A professionally organized collection of \\*\\*[\\d,]+\\s+n8n workflows\\*\\*',\n         f'A professionally organized collection of **{stats[\"total_workflows\"]:,} n8n workflows**'),\n\n        # Total workflows in various contexts\n        (r'- \\*\\*[\\d,]+\\s+workflows\\*\\* with meaningful',\n         f'- **{stats[\"total_workflows\"]:,} workflows** with meaningful'),\n\n        # Statistics section\n        (r'- \\*\\*Total Workflows\\*\\*: [\\d,]+',\n         f'- **Total Workflows**: {stats[\"total_workflows\"]:,}'),\n\n        (r'- \\*\\*Active Workflows\\*\\*: [\\d,]+ \\([\\d.]+%',\n         f'- **Active Workflows**: {stats[\"active_workflows\"]:,} ({(stats[\"active_workflows\"]/stats[\"total_workflows\"]*100):.1f}%'),\n\n        (r'- \\*\\*Total Nodes\\*\\*: [\\d,]+ \\(avg [\\d.]+ nodes',\n         f'- **Total Nodes**: {stats[\"total_nodes\"]:,} (avg {(stats[\"total_nodes\"]/stats[\"total_workflows\"]):.1f} nodes'),\n\n        (r'- \\*\\*Unique Integrations\\*\\*: [\\d,]+ different',\n         f'- **Unique Integrations**: {stats[\"unique_integrations\"]:,} different'),\n\n        # Update complexity/trigger distribution\n        (r'- \\*\\*Complex\\*\\*: [\\d,]+ workflows \\([\\d.]+%\\)',\n         f'- **Complex**: {stats[\"triggers\"].get(\"Complex\", 0):,} workflows ({(stats[\"triggers\"].get(\"Complex\", 0)/stats[\"total_workflows\"]*100):.1f}%)'),\n\n        (r'- \\*\\*Webhook\\*\\*: [\\d,]+ workflows \\([\\d.]+%\\)',\n         f'- **Webhook**: {stats[\"triggers\"].get(\"Webhook\", 0):,} workflows ({(stats[\"triggers\"].get(\"Webhook\", 0)/stats[\"total_workflows\"]*100):.1f}%)'),\n\n        (r'- \\*\\*Manual\\*\\*: [\\d,]+ workflows \\([\\d.]+%\\)',\n         f'- **Manual**: {stats[\"triggers\"].get(\"Manual\", 0):,} workflows ({(stats[\"triggers\"].get(\"Manual\", 0)/stats[\"total_workflows\"]*100):.1f}%)'),\n\n        (r'- \\*\\*Scheduled\\*\\*: [\\d,]+ workflows \\([\\d.]+%\\)',\n         f'- **Scheduled**: {stats[\"triggers\"].get(\"Scheduled\", 0):,} workflows ({(stats[\"triggers\"].get(\"Scheduled\", 0)/stats[\"total_workflows\"]*100):.1f}%)'),\n\n        # Update total in current collection stats\n        (r'\\*\\*Total Workflows\\*\\*: [\\d,]+ automation',\n         f'**Total Workflows**: {stats[\"total_workflows\"]:,} automation'),\n\n        (r'\\*\\*Active Workflows\\*\\*: [\\d,]+ \\([\\d.]+% active',\n         f'**Active Workflows**: {stats[\"active_workflows\"]:,} ({(stats[\"active_workflows\"]/stats[\"total_workflows\"]*100):.1f}% active'),\n\n        (r'\\*\\*Total Nodes\\*\\*: [\\d,]+ \\(avg [\\d.]+ nodes',\n         f'**Total Nodes**: {stats[\"total_nodes\"]:,} (avg {(stats[\"total_nodes\"]/stats[\"total_workflows\"]):.1f} nodes'),\n\n        (r'\\*\\*Unique Integrations\\*\\*: [\\d,]+ different',\n         f'**Unique Integrations**: {stats[\"unique_integrations\"]:,} different'),\n\n        # Categories count\n        (r'Our system automatically categorizes workflows into [\\d]+ service categories',\n         f'Our system automatically categorizes workflows into {stats[\"categories_count\"]} service categories'),\n\n        # Update any \"2000+\" references\n        (r'2000\\+', f'{stats[\"total_workflows\"]:,}+'),\n        (r'2,000\\+', f'{stats[\"total_workflows\"]:,}+'),\n\n        # Search across X workflows\n        (r'Search across [\\d,]+ workflows', f'Search across {stats[\"total_workflows\"]:,} workflows'),\n\n        # Instant search across X workflows\n        (r'Instant search across [\\d,]+ workflows', f'Instant search across {stats[\"total_workflows\"]:,} workflows'),\n    ]\n\n    # Apply all replacements\n    updated_content = content\n    replacements_made = 0\n\n    for pattern, replacement in replacements:\n        old_content = updated_content\n        updated_content = re.sub(pattern, replacement, updated_content)\n        if updated_content != old_content:\n            replacements_made += 1\n\n    # Write back to file\n    with open(readme_path, 'w', encoding='utf-8') as f:\n        f.write(updated_content)\n\n    print(f\"README.md updated with current statistics:\")\n    print(f\"  - Total workflows: {stats['total_workflows']:,}\")\n    print(f\"  - Active workflows: {stats['active_workflows']:,}\")\n    print(f\"  - Total nodes: {stats['total_nodes']:,}\")\n    print(f\"  - Unique integrations: {stats['unique_integrations']:,}\")\n    print(f\"  - Categories: {stats['categories_count']}\")\n    print(f\"  - Replacements made: {replacements_made}\")\n\n    return True",
    "source": "github_repo:Zie619/n8n-workflows",
    "file": "scripts/update_readme_stats.py",
    "license": "MIT",
    "language": "python"
}