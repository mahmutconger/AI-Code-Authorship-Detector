{
    "code": "def collect_learnings(\n    prompt: Prompt,\n    model: str,\n    temperature: float,\n    config: any,\n    memory: DiskMemory,\n    review: Review,\n):\n    \"\"\"\n    Collect the learning data and send it to RudderStack for analysis.\n\n    Parameters\n    ----------\n    prompt : str\n        The initial prompt or question that was provided to the model.\n    model : str\n        The name of the model used for generating the response.\n    temperature : float\n        The temperature setting used in the model's response generation.\n    config : any\n        Configuration parameters used for the learning session.\n    memory : DiskMemory\n        An instance of DiskMemory for storing and retrieving data.\n    review : Review\n        An instance of Review containing human feedback on the model's response.\n\n    Notes\n    -----\n    This function attempts to send the learning data to RudderStack. If the data size exceeds\n    the maximum allowed size, it trims the data and retries sending it.\n    \"\"\"\n    learnings = extract_learning(prompt, model, temperature, config, memory, review)\n    try:\n        send_learning(learnings)\n    except RuntimeError:\n        # try to remove some parts of learning that might be too big\n        # rudderstack max event size is 32kb\n        max_size = 32 << 10  # 32KB in bytes\n        current_size = len(learnings.to_json().encode(\"utf-8\"))  # get size in bytes\n\n        overflow = current_size - max_size\n\n        # Add some extra characters for the \"[REMOVED...]\" string and for safety margin\n        remove_length = overflow + len(f\"[REMOVED {overflow} CHARACTERS]\") + 100\n\n        learnings.logs = (\n            learnings.logs[:-remove_length]\n            + f\"\\n\\n[REMOVED {remove_length} CHARACTERS]\"\n        )\n\n        print(\n            \"WARNING: learning too big, removing some parts. \"\n            \"Please report if this results in a crash.\"\n        )\n        try:\n            send_learning(learnings)\n        except RuntimeError:\n            print(\n                \"Sending learnings crashed despite truncation. Progressing without saving learnings.\"\n            )",
    "source": "github_repo:AntonOsika/gpt-engineer",
    "file": "gpt_engineer/applications/cli/collect.py",
    "license": "MIT",
    "language": "python"
}