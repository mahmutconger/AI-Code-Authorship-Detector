{
    "code": "def start_vc(self):\n        torch.cuda.empty_cache()\n        self.flag_vc = True\n        self.rvc = rvc_for_realtime.RVC(\n            self.gui_config.pitch,\n            self.gui_config.pth_path,\n            self.gui_config.index_path,\n            self.gui_config.index_rate,\n            0,\n            0,\n            0,\n            self.config,\n            self.rvc if self.rvc else None,\n        )\n        self.gui_config.samplerate = self.rvc.tgt_sr\n        self.zc = self.rvc.tgt_sr // 100\n        self.block_frame = (\n            int(\n                np.round(\n                    self.gui_config.block_time\n                    * self.gui_config.samplerate\n                    / self.zc\n                )\n            )\n            * self.zc\n        )\n        self.block_frame_16k = 160 * self.block_frame // self.zc\n        self.crossfade_frame = (\n            int(\n                np.round(\n                    self.gui_config.crossfade_time\n                    * self.gui_config.samplerate\n                    / self.zc\n                )\n            )\n            * self.zc\n        )\n        self.sola_search_frame = self.zc\n        self.extra_frame = (\n            int(\n                np.round(\n                    self.gui_config.extra_time\n                    * self.gui_config.samplerate\n                    / self.zc\n                )\n            )\n            * self.zc\n        )\n        self.input_wav = torch.zeros(\n            self.extra_frame + self.crossfade_frame + self.sola_search_frame + self.block_frame,\n            device=self.config.device,\n            dtype=torch.float32,\n        )\n        self.input_wav_res = torch.zeros(\n            160 * self.input_wav.shape[0] // self.zc,\n            device=self.config.device,\n            dtype=torch.float32,\n        )\n        self.pitch = np.zeros(self.input_wav.shape[0] // self.zc, dtype=\"int32\")\n        self.pitchf = np.zeros(self.input_wav.shape[0] // self.zc, dtype=\"float64\")\n        self.sola_buffer = torch.zeros(self.crossfade_frame, device=self.config.device, dtype=torch.float32)\n        self.nr_buffer = self.sola_buffer.clone()\n        self.output_buffer = self.input_wav.clone()\n        self.res_buffer = torch.zeros(2 * self.zc, device=self.config.device, dtype=torch.float32)\n        self.valid_rate = 1 - (self.extra_frame - 1) / self.input_wav.shape[0]\n        self.fade_in_window = (\n            torch.sin(0.5 * np.pi * torch.linspace(0.0, 1.0, steps=self.crossfade_frame, device=self.config.device, dtype=torch.float32)) ** 2\n        )\n        self.fade_out_window = 1 - self.fade_in_window\n        self.resampler = tat.Resample(\n            orig_freq=self.gui_config.samplerate,\n            new_freq=16000,\n            dtype=torch.float32,\n        ).to(self.config.device)\n        self.tg = TorchGate(\n            sr=self.gui_config.samplerate, n_fft=4 * self.zc, prop_decrease=0.9\n        ).to(self.config.device)\n        thread_vc = threading.Thread(target=self.soundinput)\n        thread_vc.start()",
    "source": "github_repo:RVC-Project/Retrieval-based-Voice-Conversion-WebUI",
    "file": "api_231006.py",
    "license": "MIT",
    "language": "python"
}