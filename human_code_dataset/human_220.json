{
    "code": "def precompute_freqs_cis(args: ModelArgs) -> torch.Tensor:\n    \"\"\"\n    Precomputes frequency-based complex exponential values for rotary positional embeddings.\n\n    Args:\n        args (ModelArgs): Model arguments containing positional embedding parameters.\n\n    Returns:\n        torch.Tensor: Precomputed complex exponential values for positional embeddings.\n    \"\"\"\n    dim = args.qk_rope_head_dim\n    seqlen = args.max_seq_len\n    beta_fast = args.beta_fast\n    beta_slow = args.beta_slow\n    base = args.rope_theta\n    factor = args.rope_factor\n\n    def find_correction_dim(num_rotations, dim, base, max_seq_len):\n        \"\"\"\n        Computes the correction dimension for a given number of rotations in the rotary positional embedding.\n\n        Args:\n            num_rotations (float): Number of rotations to compute the correction for.\n            dim (int): Dimensionality of the embedding space.\n            base (float): Base value for the exponential computation.\n            max_seq_len (int): Maximum sequence length.\n\n        Returns:\n            float: The correction dimension based on the input parameters.\n        \"\"\"\n        return dim * math.log(max_seq_len / (num_rotations * 2 * math.pi)) / (2 * math.log(base))\n\n    def find_correction_range(low_rot, high_rot, dim, base, max_seq_len):\n        \"\"\"\n        Computes the range of correction dimensions for rotary positional embeddings.\n\n        Args:\n            low_rot (float): Lower bound for the number of rotations.\n            high_rot (float): Upper bound for the number of rotations.\n            dim (int): Dimensionality of the embedding space.\n            base (float): Base value for the exponential computation.\n            max_seq_len (int): Maximum sequence length.\n\n        Returns:\n            Tuple[int, int]: The range of correction dimensions (low, high), clamped to valid indices.\n        \"\"\"\n        low = math.floor(find_correction_dim(low_rot, dim, base, max_seq_len))\n        high = math.ceil(find_correction_dim(high_rot, dim, base, max_seq_len))\n        return max(low, 0), min(high, dim-1)\n\n    def linear_ramp_factor(min, max, dim):\n        \"\"\"\n        Computes a linear ramp function used to smooth values between a minimum and maximum range.\n\n        Args:\n            min (float): Minimum value for the ramp function.\n            max (float): Maximum value for the ramp function.\n            dim (int): Dimensionality of the ramp tensor.\n\n        Returns:\n            torch.Tensor: A tensor of shape (dim,) with values linearly interpolated between 0 and 1,\n                clamped to the range [0, 1].\n        \"\"\"\n        if min == max:\n            max += 0.001\n        linear_func = (torch.arange(dim, dtype=torch.float32) - min) / (max - min)\n        ramp_func = torch.clamp(linear_func, 0, 1)\n        return ramp_func\n\n    freqs = 1.0 / (base ** (torch.arange(0, dim, 2, dtype=torch.float32) / dim))\n    if seqlen > args.original_seq_len:\n        low, high = find_correction_range(beta_fast, beta_slow, dim, base, args.original_seq_len)\n        smooth = 1 - linear_ramp_factor(low, high, dim // 2)\n        freqs = freqs / factor * (1 - smooth) + freqs * smooth\n\n    t = torch.arange(seqlen)\n    freqs = torch.outer(t, freqs)\n    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)\n    return freqs_cis",
    "source": "github_repo:deepseek-ai/DeepSeek-V3",
    "file": "inference/model.py",
    "license": "MIT",
    "language": "python"
}