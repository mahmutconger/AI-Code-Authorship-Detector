{
    "code": "class DistAdamW(torch.optim.Optimizer):\n    \"\"\"\n    Distributed AdamW optimizer.\n    In the style of ZeRO-2, i.e. sharded optimizer states and gradient reduction\n    \"\"\"\n    def __init__(self, param_groups, lr: float = 1e-3, betas: tuple[float, float] = (0.9, 0.999), eps: float = 1e-8, weight_decay: float = 0.01):\n        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n        super().__init__(param_groups, defaults)\n\n    @torch.compile\n    @torch.no_grad()\n    def step(self):\n        rank = dist.get_rank()\n        world_size = dist.get_world_size()\n        reduce_scatter_futures: list[torch.Future] = []\n        all_reduce_futures: list[torch.Future] = []\n        grad_slices = []\n        for group in self.param_groups:\n            params: list[Tensor] = group[\"params\"]\n            for base_i in range(len(params)):\n                grad = params[base_i].grad\n                rank_size = grad.shape[0] // world_size\n                grad_slice = torch.empty_like(grad[:rank_size])\n                reduce_scatter_futures.append(dist.reduce_scatter_tensor(grad_slice, grad, op=dist.ReduceOp.AVG, async_op=True).get_future())\n                grad_slices.append(grad_slice)\n\n        idx = 0\n        for group in self.param_groups:\n            beta1, beta2 = group['betas']\n            eps = group['eps']\n            wd = group['weight_decay']\n            params = group['params']\n            for base in range(len(params)):\n                reduce_scatter_futures[idx].wait()\n                p = params[base]\n                rank_size = p.shape[0] // world_size\n                p_slice = p[rank * rank_size:(rank + 1) * rank_size]\n                lr = group['lr'] * getattr(p, \"lr_mul\", 1.0)\n                state = self.state[p]\n                g_slice = grad_slices[idx]\n                # State init\n                if not state:\n                    state['step'] = torch.tensor(0, dtype=torch.int64, device=p.device)\n                    state['exp_avg'] = torch.zeros_like(p_slice)\n                    state['exp_avg_sq'] = torch.zeros_like(p_slice)\n                exp_avg = state['exp_avg']\n                exp_avg_sq = state['exp_avg_sq']\n                state['step'] += 1\n                t = state['step']\n                # weight decay\n                if wd != 0:\n                    eff_weight_decay = lr * wd * getattr(p, \"wd_mul\", 1.0)\n                    p_slice.mul_(1 - eff_weight_decay)\n                # update running averages\n                exp_avg.mul_(beta1).add_(g_slice, alpha=1 - beta1)\n                exp_avg_sq.mul_(beta2).addcmul_(g_slice, g_slice, value=1 - beta2)\n                # bias corrections\n                bias1 = 1 - beta1 ** t\n                bias2 = 1 - beta2 ** t\n                # compute step\n                denom = exp_avg_sq.sqrt().add_(eps)\n                step_size = lr * (torch.sqrt(bias2) / bias1)\n                update = exp_avg.div(denom).mul_(step_size)\n                p_slice.add_(other=update, alpha=-1.0)\n                idx += 1\n                all_reduce_futures.append(dist.all_gather_into_tensor(p, p_slice, async_op=True).get_future())\n        torch.futures.collect_all(all_reduce_futures).wait()",
    "source": "github_repo:karpathy/nanochat",
    "file": "nanochat/adamw.py",
    "license": "MIT",
    "language": "python"
}