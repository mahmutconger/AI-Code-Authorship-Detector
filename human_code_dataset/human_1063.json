{
    "code": "class T2SBlock:\n    def __init__(\n        self,\n        num_heads,\n        hidden_dim: int,\n        mlp: T2SMLP,\n        qkv_w,\n        qkv_b,\n        out_w,\n        out_b,\n        norm_w1,\n        norm_b1,\n        norm_eps1,\n        norm_w2,\n        norm_b2,\n        norm_eps2,\n    ):\n        self.num_heads = num_heads\n        self.mlp = mlp\n        self.hidden_dim: int = hidden_dim\n        self.qkv_w = qkv_w\n        self.qkv_b = qkv_b\n        self.out_w = out_w\n        self.out_b = out_b\n        self.norm_w1 = norm_w1\n        self.norm_b1 = norm_b1\n        self.norm_eps1 = norm_eps1\n        self.norm_w2 = norm_w2\n        self.norm_b2 = norm_b2\n        self.norm_eps2 = norm_eps2\n\n        self.false = torch.tensor(False, dtype=torch.bool)\n\n    @torch.jit.ignore\n    def to_mask(\n        self,\n        x: torch.Tensor,\n        padding_mask: Optional[torch.Tensor],\n    ):\n        if padding_mask is None:\n            return x\n\n        if padding_mask.dtype == torch.bool:\n            return x.masked_fill(padding_mask, 0)\n        else:\n            return x * padding_mask\n\n    def process_prompt(\n        self,\n        x: torch.Tensor,\n        attn_mask: torch.Tensor,\n        padding_mask: Optional[torch.Tensor] = None,\n        torch_sdpa: bool = True,\n    ):\n        q, k, v = F.linear(self.to_mask(x, padding_mask), self.qkv_w, self.qkv_b).chunk(3, dim=-1)\n\n        batch_size = q.shape[0]\n        q_len = q.shape[1]\n        kv_len = k.shape[1]\n\n        q = self.to_mask(q, padding_mask)\n        k_cache = self.to_mask(k, padding_mask)\n        v_cache = self.to_mask(v, padding_mask)\n\n        q = q.view(batch_size, q_len, self.num_heads, -1).transpose(1, 2)\n        k = k_cache.view(batch_size, kv_len, self.num_heads, -1).transpose(1, 2)\n        v = v_cache.view(batch_size, kv_len, self.num_heads, -1).transpose(1, 2)\n\n        if torch_sdpa:\n            attn = F.scaled_dot_product_attention(q, k, v, ~attn_mask)\n        else:\n            attn = scaled_dot_product_attention(q, k, v, attn_mask)\n\n        attn = attn.transpose(1, 2).reshape(batch_size, q_len, -1)\n        attn = F.linear(self.to_mask(attn, padding_mask), self.out_w, self.out_b)\n\n        x = x + attn\n        x = F.layer_norm(x, [self.hidden_dim], self.norm_w1, self.norm_b1, self.norm_eps1)\n        x = x + self.mlp.forward(x)\n        x = F.layer_norm(\n            x,\n            [self.hidden_dim],\n            self.norm_w2,\n            self.norm_b2,\n            self.norm_eps2,\n        )\n        return x, k_cache, v_cache\n\n    def decode_next_token(\n        self,\n        x: torch.Tensor,\n        k_cache: torch.Tensor,\n        v_cache: torch.Tensor,\n        attn_mask: torch.Tensor = None,\n        torch_sdpa: bool = True,\n    ):\n        q, k, v = F.linear(x, self.qkv_w, self.qkv_b).chunk(3, dim=-1)\n\n        k_cache = torch.cat([k_cache, k], dim=1)\n        v_cache = torch.cat([v_cache, v], dim=1)\n\n        batch_size = q.shape[0]\n        q_len = q.shape[1]\n        kv_len = k_cache.shape[1]\n\n        q = q.view(batch_size, q_len, self.num_heads, -1).transpose(1, 2)\n        k = k_cache.view(batch_size, kv_len, self.num_heads, -1).transpose(1, 2)\n        v = v_cache.view(batch_size, kv_len, self.num_heads, -1).transpose(1, 2)\n\n        if torch_sdpa:\n            attn = F.scaled_dot_product_attention(q, k, v, (~attn_mask) if attn_mask is not None else None)\n        else:\n            attn = scaled_dot_product_attention(q, k, v, attn_mask)\n\n        attn = attn.transpose(1, 2).reshape(batch_size, q_len, -1)\n        attn = F.linear(attn, self.out_w, self.out_b)\n\n        x = x + attn\n        x = F.layer_norm(\n            x,\n            [self.hidden_dim],\n            self.norm_w1,\n            self.norm_b1,\n            self.norm_eps1,\n        )\n        x = x + self.mlp.forward(x)\n        x = F.layer_norm(\n            x,\n            [self.hidden_dim],\n            self.norm_w2,\n            self.norm_b2,\n            self.norm_eps2,\n        )\n        return x, k_cache, v_cache",
    "source": "github_repo:RVC-Boss/GPT-SoVITS",
    "file": "GPT_SoVITS/AR/models/t2s_model.py",
    "license": "MIT",
    "language": "python"
}