{
    "code": "class ParallelEmbedding(nn.Module):\n    \"\"\"\n    Embedding layer with parallelism support across distributed processes.\n\n    Args:\n        vocab_size (int): Vocabulary size.\n        dim (int): Embedding dimension.\n    \"\"\"\n    def __init__(self, vocab_size: int, dim: int):\n        super().__init__()\n        self.vocab_size = vocab_size\n        self.dim = dim\n        assert vocab_size % world_size == 0, f\"Vocabulary size must be divisible by world size (world_size={world_size})\"\n        self.part_vocab_size = (vocab_size // world_size)\n        self.vocab_start_idx = rank * self.part_vocab_size\n        self.vocab_end_idx = self.vocab_start_idx + self.part_vocab_size\n        self.weight = nn.Parameter(torch.empty(self.part_vocab_size, self.dim))\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Forward pass for parallel embedding layer.\n\n        Args:\n            x (torch.Tensor): Input tensor containing token indices.\n\n        Returns:\n            torch.Tensor: Embedded representations.\n\n        Raises:\n            ValueError: If `world_size` is not defined.\n        \"\"\"\n        if world_size > 1:\n            mask = (x < self.vocab_start_idx) | (x >= self.vocab_end_idx)\n            x = x - self.vocab_start_idx\n            x[mask] = 0\n        y = F.embedding(x, self.weight)\n        if world_size > 1:\n            y[mask] = 0\n            dist.all_reduce(y)\n        return y",
    "source": "github_repo:deepseek-ai/DeepSeek-V3",
    "file": "inference/model.py",
    "license": "MIT",
    "language": "python"
}