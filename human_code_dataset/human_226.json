{
    "code": "class MoE(nn.Module):\n    \"\"\"\n    Mixture-of-Experts (MoE) module.\n\n    Attributes:\n        dim (int): Dimensionality of input features.\n        n_routed_experts (int): Total number of experts in the model.\n        n_local_experts (int): Number of experts handled locally in distributed systems.\n        n_activated_experts (int): Number of experts activated for each input.\n        gate (nn.Module): Gating mechanism to route inputs to experts.\n        experts (nn.ModuleList): List of expert modules.\n        shared_experts (nn.Module): Shared experts applied to all inputs.\n    \"\"\"\n    def __init__(self, args: ModelArgs):\n        \"\"\"\n        Initializes the MoE module.\n\n        Args:\n            args (ModelArgs): Model arguments containing MoE parameters.\n        \"\"\"\n        super().__init__()\n        self.dim = args.dim\n        assert args.n_routed_experts % world_size == 0, f\"Number of experts must be divisible by world size (world_size={world_size})\"\n        self.n_routed_experts = args.n_routed_experts\n        self.n_local_experts = args.n_routed_experts // world_size\n        self.n_activated_experts = args.n_activated_experts\n        self.experts_start_idx = rank * self.n_local_experts\n        self.experts_end_idx = self.experts_start_idx + self.n_local_experts\n        self.gate = Gate(args)\n        self.experts = nn.ModuleList([Expert(args.dim, args.moe_inter_dim) if self.experts_start_idx <= i < self.experts_end_idx else None\n                                      for i in range(self.n_routed_experts)])\n        self.shared_experts = MLP(args.dim, args.n_shared_experts * args.moe_inter_dim)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Forward pass for the MoE module.\n\n        Args:\n            x (torch.Tensor): Input tensor.\n\n        Returns:\n            torch.Tensor: Output tensor after expert routing and computation.\n        \"\"\"\n        shape = x.size()\n        x = x.view(-1, self.dim)\n        weights, indices = self.gate(x)\n        y = torch.zeros_like(x)\n        counts = torch.bincount(indices.flatten(), minlength=self.n_routed_experts).tolist()\n        for i in range(self.experts_start_idx, self.experts_end_idx):\n            if counts[i] == 0:\n                continue\n            expert = self.experts[i]\n            idx, top = torch.where(indices == i)\n            y[idx] += expert(x[idx]) * weights[idx, top, None]\n        z = self.shared_experts(x)\n        if world_size > 1:\n            dist.all_reduce(y)\n        return (y + z).view(shape)",
    "source": "github_repo:deepseek-ai/DeepSeek-V3",
    "file": "inference/model.py",
    "license": "MIT",
    "language": "python"
}