{
    "code": "def encode(self, x0, c, t_enc, use_original_steps=False, return_intermediates=None,\n               unconditional_guidance_scale=1.0, unconditional_conditioning=None, callback=None):\n        num_reference_steps = self.ddpm_num_timesteps if use_original_steps else self.ddim_timesteps.shape[0]\n\n        assert t_enc <= num_reference_steps\n        num_steps = t_enc\n\n        if use_original_steps:\n            alphas_next = self.alphas_cumprod[:num_steps]\n            alphas = self.alphas_cumprod_prev[:num_steps]\n        else:\n            alphas_next = self.ddim_alphas[:num_steps]\n            alphas = torch.tensor(self.ddim_alphas_prev[:num_steps])\n\n        x_next = x0\n        intermediates = []\n        inter_steps = []\n        for i in tqdm(range(num_steps), desc='Encoding Image'):\n            t = torch.full((x0.shape[0],), i, device=self.model.device, dtype=torch.long)\n            if unconditional_guidance_scale == 1.:\n                noise_pred = self.model.apply_model(x_next, t, c)\n            else:\n                assert unconditional_conditioning is not None\n                e_t_uncond, noise_pred = torch.chunk(\n                    self.model.apply_model(torch.cat((x_next, x_next)), torch.cat((t, t)),\n                                           torch.cat((unconditional_conditioning, c))), 2)\n                noise_pred = e_t_uncond + unconditional_guidance_scale * (noise_pred - e_t_uncond)\n\n            xt_weighted = (alphas_next[i] / alphas[i]).sqrt() * x_next\n            weighted_noise_pred = alphas_next[i].sqrt() * (\n                    (1 / alphas_next[i] - 1).sqrt() - (1 / alphas[i] - 1).sqrt()) * noise_pred\n            x_next = xt_weighted + weighted_noise_pred\n            if return_intermediates and i % (\n                    num_steps // return_intermediates) == 0 and i < num_steps - 1:\n                intermediates.append(x_next)\n                inter_steps.append(i)\n            elif return_intermediates and i >= num_steps - 2:\n                intermediates.append(x_next)\n                inter_steps.append(i)\n            if callback: callback(i)\n\n        out = {'x_encoded': x_next, 'intermediate_steps': inter_steps}\n        if return_intermediates:\n            out.update({'intermediates': intermediates})\n        return x_next, out",
    "source": "github_repo:Stability-AI/stablediffusion",
    "file": "ldm/models/diffusion/ddim.py",
    "license": "MIT",
    "language": "python"
}