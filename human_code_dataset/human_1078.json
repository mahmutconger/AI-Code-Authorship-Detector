{
    "code": "def forward_old(self, x, x_lens, y, y_lens, bert_feature):\n        \"\"\"\n        x: phoneme_ids\n        y: semantic_ids\n        \"\"\"\n        x = self.ar_text_embedding(x)\n        x = x + self.bert_proj(bert_feature.transpose(1, 2))\n        x = self.ar_text_position(x)\n        x_mask = make_pad_mask_left(x_lens)\n\n        y_mask = make_pad_mask(y_lens)\n        y_mask_int = y_mask.type(torch.int64)\n        codes = y.type(torch.int64) * (1 - y_mask_int)\n\n        # Training\n        # AR Decoder\n        y, targets = self.pad_y_eos(codes, y_mask_int, eos_id=self.EOS)\n        x_len = x_lens.max()\n        y_len = y_lens.max()\n        y_emb = self.ar_audio_embedding(y)\n        y_pos = self.ar_audio_position(y_emb)\n\n        xy_padding_mask = torch.concat([x_mask, y_mask], dim=1)\n        ar_xy_padding_mask = xy_padding_mask\n\n        x_attn_mask = F.pad(\n            torch.zeros((x_len, x_len), dtype=torch.bool, device=x.device),\n            (0, y_len),\n            value=True,\n        )\n        y_attn_mask = F.pad(\n            torch.triu(\n                torch.ones(y_len, y_len, dtype=torch.bool, device=x.device),\n                diagonal=1,\n            ),\n            (x_len, 0),\n            value=False,\n        )\n        xy_attn_mask = torch.concat([x_attn_mask, y_attn_mask], dim=0)\n        bsz, src_len = x.shape[0], x_len + y_len\n        _xy_padding_mask = (\n            ar_xy_padding_mask.view(bsz, 1, 1, src_len)\n            .expand(-1, self.num_head, -1, -1)\n            .reshape(bsz * self.num_head, 1, src_len)\n        )\n        xy_attn_mask = xy_attn_mask.logical_or(_xy_padding_mask)\n        new_attn_mask = torch.zeros_like(xy_attn_mask, dtype=x.dtype)\n        new_attn_mask.masked_fill_(xy_attn_mask, float(\"-inf\"))\n        xy_attn_mask = new_attn_mask\n        # x 和完整的 y 一次性输入模型\n        xy_pos = torch.concat([x, y_pos], dim=1)\n        xy_dec, _ = self.h(\n            (xy_pos, None),\n            mask=xy_attn_mask,\n        )\n        logits = self.ar_predict_layer(xy_dec[:, x_len-1:]).permute(0, 2, 1)\n        # loss\n        # from feiteng: 每次 duration 越多, 梯度更新也应该更多, 所以用 sum\n        loss = F.cross_entropy(logits, targets, reduction=\"sum\")\n        acc = self.ar_accuracy_metric(logits.detach(), targets).item()\n        return loss, acc",
    "source": "github_repo:RVC-Boss/GPT-SoVITS",
    "file": "GPT_SoVITS/AR/models/t2s_model.py",
    "license": "MIT",
    "language": "python"
}