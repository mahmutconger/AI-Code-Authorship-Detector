{
    "code": "def decode_next_token(\n        self,\n        x: torch.Tensor,\n        k_cache: torch.Tensor,\n        v_cache: torch.Tensor,\n        attn_mask: torch.Tensor = None,\n        torch_sdpa: bool = True,\n    ):\n        q, k, v = F.linear(x, self.qkv_w, self.qkv_b).chunk(3, dim=-1)\n\n        k_cache = torch.cat([k_cache, k], dim=1)\n        v_cache = torch.cat([v_cache, v], dim=1)\n\n        batch_size = q.shape[0]\n        q_len = q.shape[1]\n        kv_len = k_cache.shape[1]\n\n        q = q.view(batch_size, q_len, self.num_heads, -1).transpose(1, 2)\n        k = k_cache.view(batch_size, kv_len, self.num_heads, -1).transpose(1, 2)\n        v = v_cache.view(batch_size, kv_len, self.num_heads, -1).transpose(1, 2)\n\n        if torch_sdpa:\n            attn = F.scaled_dot_product_attention(q, k, v, (~attn_mask) if attn_mask is not None else None)\n        else:\n            attn = scaled_dot_product_attention(q, k, v, attn_mask)\n\n        attn = attn.transpose(1, 2).reshape(batch_size, q_len, -1)\n        attn = F.linear(attn, self.out_w, self.out_b)\n\n        x = x + attn\n        x = F.layer_norm(\n            x,\n            [self.hidden_dim],\n            self.norm_w1,\n            self.norm_b1,\n            self.norm_eps1,\n        )\n        x = x + self.mlp.forward(x)\n        x = F.layer_norm(\n            x,\n            [self.hidden_dim],\n            self.norm_w2,\n            self.norm_b2,\n            self.norm_eps2,\n        )\n        return x, k_cache, v_cache",
    "source": "github_repo:RVC-Boss/GPT-SoVITS",
    "file": "GPT_SoVITS/AR/models/t2s_model.py",
    "license": "MIT",
    "language": "python"
}