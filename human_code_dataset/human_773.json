{
    "code": "def compare_predictions(pred_dict: dict, true_label: list) -> bool:\n    \"\"\"\n    Compares each prediction against the corresponding true label.\n\n    This function checks whether the predicted values match the true values for each\n    metric. It sorts the true labels to ensure the comparison is made in the correct\n    order. The function returns True if all predictions are accurate within a small\n    tolerance for numerical values, or if string values match case-insensitively.\n\n    Args:\n        pred_dict (dict): A dictionary of predicted metrics and their values.\n        true_label (list): A list of tuples containing true metrics and their values.\n\n    Returns:\n        bool: True if all predictions match the true labels, False otherwise.\n    \"\"\"\n    sorted_true_label = sorted(true_label, key=lambda x: x[0])  # Sort true labels by metric name\n\n    for metric, true_value in sorted_true_label:\n        try:\n            true_value = float(true_value)  # Attempt to convert the true value to float\n        except ValueError:\n            true_value = true_value.replace(\",\", \"\")  # Clean the true value if conversion fails\n\n        # Check if the true value is numeric and compare with the prediction\n        if isinstance(true_value, (int, float)) and (\n            metric not in pred_dict or abs(pred_dict[metric] - true_value) > 1e-6\n        ):\n            return False  # Return False if the prediction is inaccurate\n\n        # Check if the true value is a string and compare with the prediction\n        if isinstance(true_value, str) and (\n            metric not in pred_dict or str(pred_dict[metric]).lower() != str(true_value).lower()\n        ):\n            return False  # Return False if the string prediction does not match\n\n    return True  # Return True if all predictions are accurate",
    "source": "github_repo:FoundationAgents/MetaGPT",
    "file": "examples/di/InfiAgent-DABench/DABench.py",
    "license": "MIT",
    "language": "python"
}