{
    "code": "def reply_text(self, session: BaiduWenxinSession, retry_count=0):\n        try:\n            logger.info(\"[BAIDU] model={}\".format(session.model))\n            access_token = self.get_access_token()\n            if access_token == 'None':\n                logger.warn(\"[BAIDU] access token 获取失败\")\n                return {\n                    \"total_tokens\": 0,\n                    \"completion_tokens\": 0,\n                    \"content\": 0,\n                    }\n            url = \"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/\" + session.model + \"?access_token=\" + access_token\n            headers = {\n                'Content-Type': 'application/json'\n            }\n            payload = {'messages': session.messages, 'system': self.prompt} if self.prompt_enabled else {'messages': session.messages}\n            response = requests.request(\"POST\", url, headers=headers, data=json.dumps(payload))\n            response_text = json.loads(response.text)\n            logger.info(f\"[BAIDU] response text={response_text}\")\n            res_content = response_text[\"result\"]\n            total_tokens = response_text[\"usage\"][\"total_tokens\"]\n            completion_tokens = response_text[\"usage\"][\"completion_tokens\"]\n            logger.info(\"[BAIDU] reply={}\".format(res_content))\n            return {\n                \"total_tokens\": total_tokens,\n                \"completion_tokens\": completion_tokens,\n                \"content\": res_content,\n            }\n        except Exception as e:\n            need_retry = retry_count < 2\n            logger.warn(\"[BAIDU] Exception: {}\".format(e))\n            need_retry = False\n            self.sessions.clear_session(session.session_id)\n            result = {\"total_tokens\": 0, \"completion_tokens\": 0, \"content\": \"出错了: {}\".format(e)}\n            return result",
    "source": "github_repo:zhayujie/chatgpt-on-wechat",
    "file": "bot/baidu/baidu_wenxin.py",
    "license": "MIT",
    "language": "python"
}