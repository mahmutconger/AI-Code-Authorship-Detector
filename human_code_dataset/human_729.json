{
    "code": "class MNISTCapsuleNetworkModel(nn.Module):\n    \"\"\"\n    ## Model for classifying MNIST digits\n    \"\"\"\n\n    def __init__(self):\n        super().__init__()\n        # First convolution layer has $256$, $9 \\times 9$ convolution kernels\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=256, kernel_size=9, stride=1)\n        # The second layer (Primary Capsules) s a convolutional capsule layer with $32$ channels\n        # of convolutional $8D$ capsules ($8$ features per capsule).\n        # That is, each primary capsule contains 8 convolutional units with a 9 Ã— 9 kernel and a stride of 2.\n        # In order to implement this we create a convolutional layer with $32 \\times 8$ channels and\n        # reshape and permutate its output to get the capsules of $8$ features each.\n        self.conv2 = nn.Conv2d(in_channels=256, out_channels=32 * 8, kernel_size=9, stride=2, padding=0)\n        self.squash = Squash()\n\n        # Routing layer gets the $32 \\times 6 \\times 6$ primary capsules and produces $10$ capsules.\n        # Each of the primary capsules have $8$ features, while output capsules (Digit Capsules)\n        # have $16$ features.\n        # The routing algorithm iterates $3$ times.\n        self.digit_capsules = Router(32 * 6 * 6, 10, 8, 16, 3)\n\n        # This is the decoder mentioned in the paper.\n        # It takes the outputs of the $10$ digit capsules, each with $16$ features to reproduce the\n        # image. It goes through linear layers of sizes $512$ and $1024$ with $ReLU$ activations.\n        self.decoder = nn.Sequential(\n            nn.Linear(16 * 10, 512),\n            nn.ReLU(),\n            nn.Linear(512, 1024),\n            nn.ReLU(),\n            nn.Linear(1024, 784),\n            nn.Sigmoid()\n        )\n\n    def forward(self, data: torch.Tensor):\n        \"\"\"\n        `data` are the MNIST images, with shape `[batch_size, 1, 28, 28]`\n        \"\"\"\n        # Pass through the first convolution layer.\n        # Output of this layer has shape `[batch_size, 256, 20, 20]`\n        x = F.relu(self.conv1(data))\n        # Pass through the second convolution layer.\n        # Output of this has shape `[batch_size, 32 * 8, 6, 6]`.\n        # *Note that this layer has a stride length of $2$*.\n        x = self.conv2(x)\n\n        # Resize and permutate to get the capsules\n        caps = x.view(x.shape[0], 8, 32 * 6 * 6).permute(0, 2, 1)\n        # Squash the capsules\n        caps = self.squash(caps)\n        # Take them through the router to get digit capsules.\n        # This has shape `[batch_size, 10, 16]`.\n        caps = self.digit_capsules(caps)\n\n        # Get masks for reconstructioon\n        with torch.no_grad():\n            # The prediction by the capsule network is the capsule with longest length\n            pred = (caps ** 2).sum(-1).argmax(-1)\n            # Create a mask to maskout all the other capsules\n            mask = torch.eye(10, device=data.device)[pred]\n\n        # Mask the digit capsules to get only the capsule that made the prediction and\n        # take it through decoder to get reconstruction\n        reconstructions = self.decoder((caps * mask[:, :, None]).view(x.shape[0], -1))\n        # Reshape the reconstruction to match the image dimensions\n        reconstructions = reconstructions.view(-1, 1, 28, 28)\n\n        return caps, reconstructions, pred",
    "source": "github_repo:labmlai/annotated_deep_learning_paper_implementations",
    "file": "labml_nn/capsule_networks/mnist.py",
    "license": "MIT",
    "language": "python"
}