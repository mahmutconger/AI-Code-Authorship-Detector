{
    "code": "class AliQwenBot(Bot):\n    def __init__(self):\n        super().__init__()\n        self.api_key_expired_time = self.set_api_key()\n        self.sessions = SessionManager(AliQwenSession, model=conf().get(\"model\", const.QWEN))\n\n    def api_key_client(self):\n        return broadscope_bailian.AccessTokenClient(access_key_id=self.access_key_id(), access_key_secret=self.access_key_secret())\n\n    def access_key_id(self):\n        return conf().get(\"qwen_access_key_id\")\n\n    def access_key_secret(self):\n        return conf().get(\"qwen_access_key_secret\")\n\n    def agent_key(self):\n        return conf().get(\"qwen_agent_key\")\n\n    def app_id(self):\n        return conf().get(\"qwen_app_id\")\n\n    def node_id(self):\n        return conf().get(\"qwen_node_id\", \"\")\n\n    def temperature(self):\n        return conf().get(\"temperature\", 0.2 )\n\n    def top_p(self):\n        return conf().get(\"top_p\", 1)\n\n    def reply(self, query, context=None):\n        # acquire reply content\n        if context.type == ContextType.TEXT:\n            logger.info(\"[QWEN] query={}\".format(query))\n\n            session_id = context[\"session_id\"]\n            reply = None\n            clear_memory_commands = conf().get(\"clear_memory_commands\", [\"#清除记忆\"])\n            if query in clear_memory_commands:\n                self.sessions.clear_session(session_id)\n                reply = Reply(ReplyType.INFO, \"记忆已清除\")\n            elif query == \"#清除所有\":\n                self.sessions.clear_all_session()\n                reply = Reply(ReplyType.INFO, \"所有人记忆已清除\")\n            elif query == \"#更新配置\":\n                load_config()\n                reply = Reply(ReplyType.INFO, \"配置已更新\")\n            if reply:\n                return reply\n            session = self.sessions.session_query(query, session_id)\n            logger.debug(\"[QWEN] session query={}\".format(session.messages))\n\n            reply_content = self.reply_text(session)\n            logger.debug(\n                \"[QWEN] new_query={}, session_id={}, reply_cont={}, completion_tokens={}\".format(\n                    session.messages,\n                    session_id,\n                    reply_content[\"content\"],\n                    reply_content[\"completion_tokens\"],\n                )\n            )\n            if reply_content[\"completion_tokens\"] == 0 and len(reply_content[\"content\"]) > 0:\n                reply = Reply(ReplyType.ERROR, reply_content[\"content\"])\n            elif reply_content[\"completion_tokens\"] > 0:\n                self.sessions.session_reply(reply_content[\"content\"], session_id, reply_content[\"total_tokens\"])\n                reply = Reply(ReplyType.TEXT, reply_content[\"content\"])\n            else:\n                reply = Reply(ReplyType.ERROR, reply_content[\"content\"])\n                logger.debug(\"[QWEN] reply {} used 0 tokens.\".format(reply_content))\n            return reply\n\n        else:\n            reply = Reply(ReplyType.ERROR, \"Bot不支持处理{}类型的消息\".format(context.type))\n            return reply\n\n    def reply_text(self, session: AliQwenSession, retry_count=0) -> dict:\n        \"\"\"\n        call bailian's ChatCompletion to get the answer\n        :param session: a conversation session\n        :param retry_count: retry count\n        :return: {}\n        \"\"\"\n        try:\n            prompt, history = self.convert_messages_format(session.messages)\n            self.update_api_key_if_expired()\n            # NOTE 阿里百炼的call()函数未提供temperature参数，考虑到temperature和top_p参数作用相同，取两者较小的值作为top_p参数传入，详情见文档 https://help.aliyun.com/document_detail/2587502.htm\n            response = broadscope_bailian.Completions().call(app_id=self.app_id(), prompt=prompt, history=history, top_p=min(self.temperature(), self.top_p()))\n            completion_content = self.get_completion_content(response, self.node_id())\n            completion_tokens, total_tokens = self.calc_tokens(session.messages, completion_content)\n            return {\n                \"total_tokens\": total_tokens,\n                \"completion_tokens\": completion_tokens,\n                \"content\": completion_content,\n            }\n        except Exception as e:\n            need_retry = retry_count < 2\n            result = {\"completion_tokens\": 0, \"content\": \"我现在有点累了，等会再来吧\"}\n            if isinstance(e, openai.error.RateLimitError):\n                logger.warn(\"[QWEN] RateLimitError: {}\".format(e))\n                result[\"content\"] = \"提问太快啦，请休息一下再问我吧\"\n                if need_retry:\n                    time.sleep(20)\n            elif isinstance(e, openai.error.Timeout):\n                logger.warn(\"[QWEN] Timeout: {}\".format(e))\n                result[\"content\"] = \"我没有收到你的消息\"\n                if need_retry:\n                    time.sleep(5)\n            elif isinstance(e, openai.error.APIError):\n                logger.warn(\"[QWEN] Bad Gateway: {}\".format(e))\n                result[\"content\"] = \"请再问我一次\"\n                if need_retry:\n                    time.sleep(10)\n            elif isinstance(e, openai.error.APIConnectionError):\n                logger.warn(\"[QWEN] APIConnectionError: {}\".format(e))\n                need_retry = False\n                result[\"content\"] = \"我连接不到你的网络\"\n            else:\n                logger.exception(\"[QWEN] Exception: {}\".format(e))\n                need_retry = False\n                self.sessions.clear_session(session.session_id)\n\n            if need_retry:\n                logger.warn(\"[QWEN] 第{}次重试\".format(retry_count + 1))\n                return self.reply_text(session, retry_count + 1)\n            else:\n                return result\n\n    def set_api_key(self):\n        api_key, expired_time = self.api_key_client().create_token(agent_key=self.agent_key())\n        broadscope_bailian.api_key = api_key\n        return expired_time\n\n    def update_api_key_if_expired(self):\n        if time.time() > self.api_key_expired_time:\n            self.api_key_expired_time = self.set_api_key()\n\n    def convert_messages_format(self, messages) -> Tuple[str, List[ChatQaMessage]]:\n        history = []\n        user_content = ''\n        assistant_content = ''\n        system_content = ''\n        for message in messages:\n            role = message.get('role')\n            if role == 'user':\n                user_content += message.get('content')\n            elif role == 'assistant':\n                assistant_content = message.get('content')\n                history.append(ChatQaMessage(user_content, assistant_content))\n                user_content = ''\n                assistant_content = ''\n            elif role =='system':\n                system_content += message.get('content')\n        if user_content == '':\n            raise Exception('no user message')\n        if system_content != '':\n            # NOTE 模拟系统消息，测试发现人格描述以\"你需要扮演ChatGPT\"开头能够起作用，而以\"你是ChatGPT\"开头模型会直接否认\n            system_qa = ChatQaMessage(system_content, '好的，我会严格按照你的设定回答问题')\n            history.insert(0, system_qa)\n        logger.debug(\"[QWEN] converted qa messages: {}\".format([item.to_dict() for item in history]))\n        logger.debug(\"[QWEN] user content as prompt: {}\".format(user_content))\n        return user_content, history\n\n    def get_completion_content(self, response, node_id):\n        if not response['Success']:\n            return f\"[ERROR]\\n{response['Code']}:{response['Message']}\"\n        text = response['Data']['Text']\n        if node_id == '':\n            return text\n        # TODO: 当使用流程编排创建大模型应用时，响应结构如下，最终结果在['finalResult'][node_id]['response']['text']中，暂时先这么写\n        # {\n        #     'Success': True,\n        #     'Code': None,\n        #     'Message': None,\n        #     'Data': {\n        #         'ResponseId': '9822f38dbacf4c9b8daf5ca03a2daf15',\n        #         'SessionId': 'session_id',\n        #         'Text': '{\"finalResult\":{\"LLM_T7islK\":{\"params\":{\"modelId\":\"qwen-plus-v1\",\"prompt\":\"${systemVars.query}${bizVars.Text}\"},\"response\":{\"text\":\"作为一个AI语言模型，我没有年龄，因为我没有生日。\\n我只是一个程序，没有生命和身体。\"}}}}',\n        #         'Thoughts': [],\n        #         'Debug': {},\n        #         'DocReferences': []\n        #     },\n        #     'RequestId': '8e11d31551ce4c3f83f49e6e0dd998b0',\n        #     'Failed': None\n        # }\n        text_dict = json.loads(text)\n        completion_content =  text_dict['finalResult'][node_id]['response']['text']\n        return completion_content\n\n    def calc_tokens(self, messages, completion_content):\n        completion_tokens = len(completion_content)\n        prompt_tokens = 0\n        for message in messages:\n            prompt_tokens += len(message[\"content\"])\n        return completion_tokens, prompt_tokens + completion_tokens",
    "source": "github_repo:zhayujie/chatgpt-on-wechat",
    "file": "bot/ali/ali_qwen_bot.py",
    "license": "MIT",
    "language": "python"
}