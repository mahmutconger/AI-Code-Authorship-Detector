{
    "code": "class LatentUpscaleDiffusion(LatentDiffusion):\n    def __init__(self, *args, low_scale_config, low_scale_key=\"LR\", noise_level_key=None, **kwargs):\n        super().__init__(*args, **kwargs)\n        # assumes that neither the cond_stage nor the low_scale_model contain trainable params\n        assert not self.cond_stage_trainable\n        self.instantiate_low_stage(low_scale_config)\n        self.low_scale_key = low_scale_key\n        self.noise_level_key = noise_level_key\n\n    def instantiate_low_stage(self, config):\n        model = instantiate_from_config(config)\n        self.low_scale_model = model.eval()\n        self.low_scale_model.train = disabled_train\n        for param in self.low_scale_model.parameters():\n            param.requires_grad = False\n\n    @torch.no_grad()\n    def get_input(self, batch, k, cond_key=None, bs=None, log_mode=False):\n        if not log_mode:\n            z, c = super().get_input(batch, k, force_c_encode=True, bs=bs)\n        else:\n            z, c, x, xrec, xc = super().get_input(batch, self.first_stage_key, return_first_stage_outputs=True,\n                                                  force_c_encode=True, return_original_cond=True, bs=bs)\n        x_low = batch[self.low_scale_key][:bs]\n        x_low = rearrange(x_low, 'b h w c -> b c h w')\n        x_low = x_low.to(memory_format=torch.contiguous_format).float()\n        zx, noise_level = self.low_scale_model(x_low)\n        if self.noise_level_key is not None:\n            # get noise level from batch instead, e.g. when extracting a custom noise level for bsr\n            raise NotImplementedError('TODO')\n\n        all_conds = {\"c_concat\": [zx], \"c_crossattn\": [c], \"c_adm\": noise_level}\n        if log_mode:\n            # TODO: maybe disable if too expensive\n            x_low_rec = self.low_scale_model.decode(zx)\n            return z, all_conds, x, xrec, xc, x_low, x_low_rec, noise_level\n        return z, all_conds\n\n    @torch.no_grad()\n    def log_images(self, batch, N=8, n_row=4, sample=True, ddim_steps=200, ddim_eta=1., return_keys=None,\n                   plot_denoise_rows=False, plot_progressive_rows=True, plot_diffusion_rows=True,\n                   unconditional_guidance_scale=1., unconditional_guidance_label=None, use_ema_scope=True,\n                   **kwargs):\n        ema_scope = self.ema_scope if use_ema_scope else nullcontext\n        use_ddim = ddim_steps is not None\n\n        log = dict()\n        z, c, x, xrec, xc, x_low, x_low_rec, noise_level = self.get_input(batch, self.first_stage_key, bs=N,\n                                                                          log_mode=True)\n        N = min(x.shape[0], N)\n        n_row = min(x.shape[0], n_row)\n        log[\"inputs\"] = x\n        log[\"reconstruction\"] = xrec\n        log[\"x_lr\"] = x_low\n        log[f\"x_lr_rec_@noise_levels{'-'.join(map(lambda x: str(x), list(noise_level.cpu().numpy())))}\"] = x_low_rec\n        if self.model.conditioning_key is not None:\n            if hasattr(self.cond_stage_model, \"decode\"):\n                xc = self.cond_stage_model.decode(c)\n                log[\"conditioning\"] = xc\n            elif self.cond_stage_key in [\"caption\", \"txt\"]:\n                xc = log_txt_as_img((x.shape[2], x.shape[3]), batch[self.cond_stage_key], size=x.shape[2] // 25)\n                log[\"conditioning\"] = xc\n            elif self.cond_stage_key in ['class_label', 'cls']:\n                xc = log_txt_as_img((x.shape[2], x.shape[3]), batch[\"human_label\"], size=x.shape[2] // 25)\n                log['conditioning'] = xc\n            elif isimage(xc):\n                log[\"conditioning\"] = xc\n            if ismap(xc):\n                log[\"original_conditioning\"] = self.to_rgb(xc)\n\n        if plot_diffusion_rows:\n            # get diffusion row\n            diffusion_row = list()\n            z_start = z[:n_row]\n            for t in range(self.num_timesteps):\n                if t % self.log_every_t == 0 or t == self.num_timesteps - 1:\n                    t = repeat(torch.tensor([t]), '1 -> b', b=n_row)\n                    t = t.to(self.device).long()\n                    noise = torch.randn_like(z_start)\n                    z_noisy = self.q_sample(x_start=z_start, t=t, noise=noise)\n                    diffusion_row.append(self.decode_first_stage(z_noisy))\n\n            diffusion_row = torch.stack(diffusion_row)  # n_log_step, n_row, C, H, W\n            diffusion_grid = rearrange(diffusion_row, 'n b c h w -> b n c h w')\n            diffusion_grid = rearrange(diffusion_grid, 'b n c h w -> (b n) c h w')\n            diffusion_grid = make_grid(diffusion_grid, nrow=diffusion_row.shape[0])\n            log[\"diffusion_row\"] = diffusion_grid\n\n        if sample:\n            # get denoise row\n            with ema_scope(\"Sampling\"):\n                samples, z_denoise_row = self.sample_log(cond=c, batch_size=N, ddim=use_ddim,\n                                                         ddim_steps=ddim_steps, eta=ddim_eta)\n                # samples, z_denoise_row = self.sample(cond=c, batch_size=N, return_intermediates=True)\n            x_samples = self.decode_first_stage(samples)\n            log[\"samples\"] = x_samples\n            if plot_denoise_rows:\n                denoise_grid = self._get_denoise_row_from_list(z_denoise_row)\n                log[\"denoise_row\"] = denoise_grid\n\n        if unconditional_guidance_scale > 1.0:\n            uc_tmp = self.get_unconditional_conditioning(N, unconditional_guidance_label)\n            # TODO explore better \"unconditional\" choices for the other keys\n            # maybe guide away from empty text label and highest noise level and maximally degraded zx?\n            uc = dict()\n            for k in c:\n                if k == \"c_crossattn\":\n                    assert isinstance(c[k], list) and len(c[k]) == 1\n                    uc[k] = [uc_tmp]\n                elif k == \"c_adm\":  # todo: only run with text-based guidance?\n                    assert isinstance(c[k], torch.Tensor)\n                    #uc[k] = torch.ones_like(c[k]) * self.low_scale_model.max_noise_level\n                    uc[k] = c[k]\n                elif isinstance(c[k], list):\n                    uc[k] = [c[k][i] for i in range(len(c[k]))]\n                else:\n                    uc[k] = c[k]\n\n            with ema_scope(\"Sampling with classifier-free guidance\"):\n                samples_cfg, _ = self.sample_log(cond=c, batch_size=N, ddim=use_ddim,\n                                                 ddim_steps=ddim_steps, eta=ddim_eta,\n                                                 unconditional_guidance_scale=unconditional_guidance_scale,\n                                                 unconditional_conditioning=uc,\n                                                 )\n                x_samples_cfg = self.decode_first_stage(samples_cfg)\n                log[f\"samples_cfg_scale_{unconditional_guidance_scale:.2f}\"] = x_samples_cfg\n\n        if plot_progressive_rows:\n            with ema_scope(\"Plotting Progressives\"):\n                img, progressives = self.progressive_denoising(c,\n                                                               shape=(self.channels, self.image_size, self.image_size),\n                                                               batch_size=N)\n            prog_row = self._get_denoise_row_from_list(progressives, desc=\"Progressive Generation\")\n            log[\"progressive_row\"] = prog_row\n\n        return log",
    "source": "github_repo:Stability-AI/stablediffusion",
    "file": "ldm/models/diffusion/ddpm.py",
    "license": "MIT",
    "language": "python"
}