{
    "code": "class RegularizationLoss(nn.Module):\n    \"\"\"\n    ## Regularization loss\n\n    $$L_{Reg} = \\mathop{KL} \\Big(p_n \\Vert p_G(\\lambda_p) \\Big)$$\n\n    $\\mathop{KL}$ is the [Kullbackâ€“Leibler divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence).\n\n    $p_G$ is the [Geometric distribution](https://en.wikipedia.org/wiki/Geometric_distribution) parameterized by\n    $\\lambda_p$. *$\\lambda_p$ has nothing to do with $\\lambda_n$; we are just sticking to same notation as the paper*.\n    $$Pr_{p_G(\\lambda_p)}(X = k) = (1 - \\lambda_p)^k \\lambda_p$$.\n\n    The regularization loss biases the network towards taking $\\frac{1}{\\lambda_p}$ steps and incentivies non-zero probabilities\n    for all steps; i.e. promotes exploration.\n    \"\"\"\n\n    def __init__(self, lambda_p: float, max_steps: int = 1_000):\n        \"\"\"\n        * `lambda_p` is $\\lambda_p$ - the success probability of geometric distribution\n        * `max_steps` is the highest $N$; we use this to pre-compute $p_G(\\lambda_p)$\n        \"\"\"\n        super().__init__()\n\n        # Empty vector to calculate $p_G(\\lambda_p)$\n        p_g = torch.zeros((max_steps,))\n        # $(1 - \\lambda_p)^k$\n        not_halted = 1.\n        # Iterate upto `max_steps`\n        for k in range(max_steps):\n            # $$Pr_{p_G(\\lambda_p)}(X = k) = (1 - \\lambda_p)^k \\lambda_p$$\n            p_g[k] = not_halted * lambda_p\n            # Update $(1 - \\lambda_p)^k$\n            not_halted = not_halted * (1 - lambda_p)\n\n        # Save $Pr_{p_G(\\lambda_p)}$\n        self.p_g = nn.Parameter(p_g, requires_grad=False)\n\n        # KL-divergence loss\n        self.kl_div = nn.KLDivLoss(reduction='batchmean')\n\n    def forward(self, p: torch.Tensor):\n        \"\"\"\n        * `p` is $p_1 \\dots p_N$ in a tensor of shape `[N, batch_size]`\n        \"\"\"\n        # Transpose `p` to `[batch_size, N]`\n        p = p.transpose(0, 1)\n        # Get $Pr_{p_G(\\lambda_p)}$ upto $N$ and expand it across the batch dimension\n        p_g = self.p_g[None, :p.shape[1]].expand_as(p)\n\n        # Calculate the KL-divergence.\n        # *The [PyTorch KL-divergence](https://pytorch.org/docs/stable/generated/torch.nn.KLDivLoss.html)\n        # implementation accepts log probabilities.*\n        return self.kl_div(p.log(), p_g)",
    "source": "github_repo:labmlai/annotated_deep_learning_paper_implementations",
    "file": "labml_nn/adaptive_computation/ponder_net/__init__.py",
    "license": "MIT",
    "language": "python"
}