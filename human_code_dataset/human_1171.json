{
    "code": "def process(example):\n        ids = enc.encode_ordinary(example['text']) # encode_ordinary ignores any special tokens\n        ids.append(enc.eot_token) # add the end of text token, e.g. 50256 for gpt2 bpe\n        # note: I think eot should be prepended not appended... hmm. it's called \"eot\" though...\n        out = {'ids': ids, 'len': len(ids)}\n        return out",
    "source": "github_repo:karpathy/nanoGPT",
    "file": "data/openwebtext/prepare.py",
    "license": "MIT",
    "language": "python"
}