{
    "code": "class Linear(nn.Module):\n    \"\"\"\n    Custom linear layer with support for quantized weights and optional bias.\n\n    Args:\n        in_features (int): Number of input features.\n        out_features (int): Number of output features.\n        bias (bool): Whether to include a bias term. Defaults to False.\n        dtype (optional): Data type for the layer. Defaults to `torch.bfloat16`.\n    \"\"\"\n    dtype = torch.bfloat16\n    scale_fmt: Optional[str] = None\n\n    def __init__(self, in_features: int, out_features: int, bias: bool = False, dtype = None):\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.weight = nn.Parameter(torch.empty(out_features, in_features, dtype=dtype or Linear.dtype))\n        if self.weight.element_size() == 1:\n            scale_out_features = (out_features + block_size - 1) // block_size\n            scale_in_features = (in_features + block_size - 1) // block_size\n            self.weight.scale = self.scale = nn.Parameter(torch.empty(scale_out_features, scale_in_features, dtype=torch.float32))\n        else:\n            self.register_parameter(\"scale\", None)\n        if bias:\n            self.bias = nn.Parameter(torch.empty(out_features))\n        else:\n            self.register_parameter(\"bias\", None)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Forward pass for the custom linear layer.\n\n        Args:\n            x (torch.Tensor): Input tensor.\n\n        Returns:\n            torch.Tensor: Transformed tensor after linear computation.\n        \"\"\"\n        return linear(x, self.weight, self.bias, self.scale_fmt)",
    "source": "github_repo:deepseek-ai/DeepSeek-V3",
    "file": "inference/model.py",
    "license": "MIT",
    "language": "python"
}