{
    "code": "def start_vc(self):\n        torch.cuda.empty_cache()\n        self.flag_vc = True\n        self.rvc = rvc_for_realtime.RVC(\n            self.gui_config.pitch,\n            self.gui_config.pth_path,\n            self.gui_config.index_path,\n            self.gui_config.index_rate,\n            self.gui_config.n_cpu,\n            self.inp_q,\n            self.opt_q,\n            self.config,\n            self.rvc if self.rvc else None,\n        )\n        self.gui_config.samplerate = (\n            self.rvc.tgt_sr\n            if self.gui_config.sr_type == \"sr_model\"\n            else self.get_device_samplerate()\n        )\n        self.zc = self.gui_config.samplerate // 100\n        self.block_frame = (\n            int(\n                np.round(\n                    self.gui_config.block_time\n                    * self.gui_config.samplerate\n                    / self.zc\n                )\n            )\n            * self.zc\n        )\n        self.block_frame_16k = 160 * self.block_frame // self.zc\n        self.crossfade_frame = (\n            int(\n                np.round(\n                    self.gui_config.crossfade_time\n                    * self.gui_config.samplerate\n                    / self.zc\n                )\n            )\n            * self.zc\n        )\n        self.sola_buffer_frame = min(self.crossfade_frame, 4 * self.zc)\n        self.sola_search_frame = self.zc\n        self.extra_frame = (\n            int(\n                np.round(\n                    self.gui_config.extra_time\n                    * self.gui_config.samplerate\n                    / self.zc\n                )\n            )\n            * self.zc\n        )\n        self.input_wav = torch.zeros(\n            self.extra_frame\n            + self.crossfade_frame\n            + self.sola_search_frame\n            + self.block_frame,\n            device=self.config.device,\n            dtype=torch.float32,\n        )\n        self.input_wav_denoise = self.input_wav.clone()\n        self.input_wav_res = torch.zeros(\n            160 * self.input_wav.shape[0] // self.zc,\n            device=self.config.device,\n            dtype=torch.float32,\n        )\n        self.rms_buffer = np.zeros(4 * self.zc, dtype=\"float32\")\n        self.sola_buffer = torch.zeros(\n            self.sola_buffer_frame, device=self.config.device, dtype=torch.float32\n        )\n        self.nr_buffer = self.sola_buffer.clone()\n        self.output_buffer = self.input_wav.clone()\n        self.skip_head = self.extra_frame // self.zc\n        self.return_length = (\n            self.block_frame + self.sola_buffer_frame + self.sola_search_frame\n        ) // self.zc\n        self.fade_in_window = (\n            torch.sin(\n                0.5\n                * np.pi\n                * torch.linspace(\n                    0.0,\n                    1.0,\n                    steps=self.sola_buffer_frame,\n                    device=self.config.device,\n                    dtype=torch.float32,\n                )\n            )\n            ** 2\n        )\n        self.fade_out_window = 1 - self.fade_in_window\n        self.resampler = tat.Resample(\n            orig_freq=self.gui_config.samplerate,\n            new_freq=16000,\n            dtype=torch.float32,\n        ).to(self.config.device)\n        if self.rvc.tgt_sr != self.gui_config.samplerate:\n            self.resampler2 = tat.Resample(\n                orig_freq=self.rvc.tgt_sr,\n                new_freq=self.gui_config.samplerate,\n                dtype=torch.float32,\n            ).to(self.config.device)\n        else:\n            self.resampler2 = None\n        self.tg = TorchGate(\n            sr=self.gui_config.samplerate, n_fft=4 * self.zc, prop_decrease=0.9\n        ).to(self.config.device)\n        thread_vc = threading.Thread(target=self.soundinput)\n        thread_vc.start()",
    "source": "github_repo:RVC-Project/Retrieval-based-Voice-Conversion-WebUI",
    "file": "api_240604.py",
    "license": "MIT",
    "language": "python"
}