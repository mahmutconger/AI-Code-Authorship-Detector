{
    "code": "class FTA(nn.Module):\n    \"\"\"\n    ### Fuzzy Tiling Activations (FTA)\n    \"\"\"\n\n    def __init__(self, lower_limit: float, upper_limit: float, delta: float, eta: float):\n        \"\"\"\n        :param lower_limit: is the lower limit $l$\n        :param upper_limit: is the upper limit $u$\n        :param delta: is the bin size $\\delta$\n        :param eta: is the parameter $\\eta$ that detemines the softness of the boundaries.\n        \"\"\"\n        super().__init__()\n        # Initialize tiling vector\n        # $$\\mathbf{c} = (l, l + \\delta, l + 2 \\delta, \\dots, u - 2 \\delta, u - \\delta)$$\n        self.c = nn.Parameter(torch.arange(lower_limit, upper_limit, delta), requires_grad=False)\n        # The input vector expands by a factor equal to the number of bins $\\frac{u - l}{\\delta}$\n        self.expansion_factor = len(self.c)\n        # $\\delta$\n        self.delta = delta\n        # $\\eta$\n        self.eta = eta\n\n    def fuzzy_i_plus(self, x: torch.Tensor):\n        \"\"\"\n        #### Fuzzy indicator function\n\n        $$I_{\\eta,+}(x) = I_+(\\eta - x) x + I_+ (x - \\eta)$$\n        \"\"\"\n        return (x <= self.eta) * x + (x > self.eta)\n\n    def forward(self, z: torch.Tensor):\n        # Add another dimension of size $1$.\n        # We will expand this into bins.\n        z = z.view(*z.shape, 1)\n\n        # $$\\phi_\\eta(z) = 1 - I_{\\eta,+} \\big( \\max(\\mathbf{c} - z, 0) + \\max(z - \\delta - \\mathbf{c}, 0) \\big)$$\n        z = 1. - self.fuzzy_i_plus(torch.clip(self.c - z, min=0.) + torch.clip(z - self.delta - self.c, min=0.))\n\n        # Reshape back to original number of dimensions.\n        # The last dimension size gets expanded by the number of bins, $\\frac{u - l}{\\delta}$.\n        return z.view(*z.shape[:-2], -1)",
    "source": "github_repo:labmlai/annotated_deep_learning_paper_implementations",
    "file": "labml_nn/activations/fta/__init__.py",
    "license": "MIT",
    "language": "python"
}