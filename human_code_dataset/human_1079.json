{
    "code": "def infer(\n        self,\n        x,\n        x_lens,\n        prompts,\n        bert_feature,\n        top_k: int = -100,\n        early_stop_num: int = -1,\n        temperature: float = 1.0,\n    ):\n        x = self.ar_text_embedding(x)\n        x = x + self.bert_proj(bert_feature.transpose(1, 2))\n        x = self.ar_text_position(x)\n\n        # AR Decoder\n        y = prompts\n        prefix_len = y.shape[1]\n        x_len = x.shape[1]\n        x_attn_mask = torch.zeros((x_len, x_len), dtype=torch.bool)\n        stop = False\n        for _ in tqdm(range(1500)):\n            y_emb = self.ar_audio_embedding(y)\n            y_pos = self.ar_audio_position(y_emb)\n            # x 和逐渐增长的 y 一起输入给模型\n            xy_pos = torch.concat([x, y_pos], dim=1)\n            y_len = y.shape[1]\n            x_attn_mask_pad = F.pad(\n                x_attn_mask,\n                (0, y_len),\n                value=True,\n            )\n            y_attn_mask = F.pad(\n                torch.triu(torch.ones(y_len, y_len, dtype=torch.bool), diagonal=1),\n                (x_len, 0),\n                value=False,\n            )\n            xy_attn_mask = torch.concat([x_attn_mask_pad, y_attn_mask], dim=0).to(y.device)\n\n            xy_dec, _ = self.h(\n                (xy_pos, None),\n                mask=xy_attn_mask,\n            )\n            logits = self.ar_predict_layer(xy_dec[:, -1])\n            samples = topk_sampling(logits, top_k=top_k, top_p=1.0, temperature=temperature)\n\n            if early_stop_num != -1 and (y.shape[1] - prefix_len) > early_stop_num:\n                print(\"use early stop num:\", early_stop_num)\n                stop = True\n\n            if torch.argmax(logits, dim=-1)[0] == self.EOS or samples[0, 0] == self.EOS:\n                # print(torch.argmax(logits, dim=-1)[0] == self.EOS, samples[0, 0] == self.EOS)\n                stop = True\n            if stop:\n                if prompts.shape[1] == y.shape[1]:\n                    y = torch.concat([y, torch.zeros_like(samples)], dim=1)\n                    print(\"bad zero prediction\")\n                print(f\"T2S Decoding EOS [{prefix_len} -> {y.shape[1]}]\")\n                break\n            # 本次生成的 semantic_ids 和之前的 y 构成新的 y\n            # print(samples.shape)#[1,1]#第一个1是bs\n            # import os\n            # os._exit(2333)\n            y = torch.concat([y, samples], dim=1)\n        return y",
    "source": "github_repo:RVC-Boss/GPT-SoVITS",
    "file": "GPT_SoVITS/AR/models/t2s_model.py",
    "license": "MIT",
    "language": "python"
}