{
    "code": "def sherlock(\n    username: str,\n    site_data: dict[str, dict[str, str]],\n    query_notify: QueryNotify,\n    dump_response: bool = False,\n    proxy: Optional[str] = None,\n    timeout: int = 60,\n) -> dict[str, dict[str, str | QueryResult]]:\n    \"\"\"Run Sherlock Analysis.\n\n    Checks for existence of username on various social media sites.\n\n    Keyword Arguments:\n    username               -- String indicating username that report\n                              should be created against.\n    site_data              -- Dictionary containing all of the site data.\n    query_notify           -- Object with base type of QueryNotify().\n                              This will be used to notify the caller about\n                              query results.\n    proxy                  -- String indicating the proxy URL\n    timeout                -- Time in seconds to wait before timing out request.\n                              Default is 60 seconds.\n\n    Return Value:\n    Dictionary containing results from report. Key of dictionary is the name\n    of the social network site, and the value is another dictionary with\n    the following keys:\n        url_main:      URL of main site.\n        url_user:      URL of user on site (if account exists).\n        status:        QueryResult() object indicating results of test for\n                       account existence.\n        http_status:   HTTP status code of query which checked for existence on\n                       site.\n        response_text: Text that came back from request.  May be None if\n                       there was an HTTP error when checking for existence.\n    \"\"\"\n\n    # Notify caller that we are starting the query.\n    query_notify.start(username)\n\n    # Normal requests\n    underlying_session = requests.session()\n\n    # Limit number of workers to 20.\n    # This is probably vastly overkill.\n    if len(site_data) >= 20:\n        max_workers = 20\n    else:\n        max_workers = len(site_data)\n\n    # Create multi-threaded session for all requests.\n    session = SherlockFuturesSession(\n        max_workers=max_workers, session=underlying_session\n    )\n\n    # Results from analysis of all sites\n    results_total = {}\n\n    # First create futures for all requests. This allows for the requests to run in parallel\n    for social_network, net_info in site_data.items():\n        # Results from analysis of this specific site\n        results_site = {\"url_main\": net_info.get(\"urlMain\")}\n\n        # Record URL of main site\n\n        # A user agent is needed because some sites don't return the correct\n        # information since they think that we are bots (Which we actually are...)\n        headers = {\n            \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:129.0) Gecko/20100101 Firefox/129.0\",\n        }\n\n        if \"headers\" in net_info:\n            # Override/append any extra headers required by a given site.\n            headers.update(net_info[\"headers\"])\n\n        # URL of user on site (if it exists)\n        url = interpolate_string(net_info[\"url\"], username.replace(' ', '%20'))\n\n        # Don't make request if username is invalid for the site\n        regex_check = net_info.get(\"regexCheck\")\n        if regex_check and re.search(regex_check, username) is None:\n            # No need to do the check at the site: this username is not allowed.\n            results_site[\"status\"] = QueryResult(\n                username, social_network, url, QueryStatus.ILLEGAL\n            )\n            results_site[\"url_user\"] = \"\"\n            results_site[\"http_status\"] = \"\"\n            results_site[\"response_text\"] = \"\"\n            query_notify.update(results_site[\"status\"])\n        else:\n            # URL of user on site (if it exists)\n            results_site[\"url_user\"] = url\n            url_probe = net_info.get(\"urlProbe\")\n            request_method = net_info.get(\"request_method\")\n            request_payload = net_info.get(\"request_payload\")\n            request = None\n\n            if request_method is not None:\n                if request_method == \"GET\":\n                    request = session.get\n                elif request_method == \"HEAD\":\n                    request = session.head\n                elif request_method == \"POST\":\n                    request = session.post\n                elif request_method == \"PUT\":\n                    request = session.put\n                else:\n                    raise RuntimeError(f\"Unsupported request_method for {url}\")\n\n            if request_payload is not None:\n                request_payload = interpolate_string(request_payload, username)\n\n            if url_probe is None:\n                # Probe URL is normal one seen by people out on the web.\n                url_probe = url\n            else:\n                # There is a special URL for probing existence separate\n                # from where the user profile normally can be found.\n                url_probe = interpolate_string(url_probe, username)\n\n            if request is None:\n                if net_info[\"errorType\"] == \"status_code\":\n                    # In most cases when we are detecting by status code,\n                    # it is not necessary to get the entire body:  we can\n                    # detect fine with just the HEAD response.\n                    request = session.head\n                else:\n                    # Either this detect method needs the content associated\n                    # with the GET response, or this specific website will\n                    # not respond properly unless we request the whole page.\n                    request = session.get\n\n            if net_info[\"errorType\"] == \"response_url\":\n                # Site forwards request to a different URL if username not\n                # found.  Disallow the redirect so we can capture the\n                # http status from the original URL request.\n                allow_redirects = False\n            else:\n                # Allow whatever redirect that the site wants to do.\n                # The final result of the request will be what is available.\n                allow_redirects = True\n\n            # This future starts running the request in a new thread, doesn't block the main thread\n            if proxy is not None:\n                proxies = {\"http\": proxy, \"https\": proxy}\n                future = request(\n                    url=url_probe,\n                    headers=headers,\n                    proxies=proxies,\n                    allow_redirects=allow_redirects,\n                    timeout=timeout,\n                    json=request_payload,\n                )\n            else:\n                future = request(\n                    url=url_probe,\n                    headers=headers,\n                    allow_redirects=allow_redirects,\n                    timeout=timeout,\n                    json=request_payload,\n                )\n\n            # Store future in data for access later\n            net_info[\"request_future\"] = future\n\n        # Add this site's results into final dictionary with all the other results.\n        results_total[social_network] = results_site\n\n    # Open the file containing account links\n    for social_network, net_info in site_data.items():\n        # Retrieve results again\n        results_site = results_total.get(social_network)\n\n        # Retrieve other site information again\n        url = results_site.get(\"url_user\")\n        status = results_site.get(\"status\")\n        if status is not None:\n            # We have already determined the user doesn't exist here\n            continue\n\n        # Get the expected error type\n        error_type = net_info[\"errorType\"]\n        if isinstance(error_type, str):\n            error_type: list[str] = [error_type]\n\n        # Retrieve future and ensure it has finished\n        future = net_info[\"request_future\"]\n        r, error_text, exception_text = get_response(\n            request_future=future, error_type=error_type, social_network=social_network\n        )\n\n        # Get response time for response of our request.\n        try:\n            response_time = r.elapsed\n        except AttributeError:\n            response_time = None\n\n        # Attempt to get request information\n        try:\n            http_status = r.status_code\n        except Exception:\n            http_status = \"?\"\n        try:\n            response_text = r.text.encode(r.encoding or \"UTF-8\")\n        except Exception:\n            response_text = \"\"\n\n        query_status = QueryStatus.UNKNOWN\n        error_context = None\n\n        # As WAFs advance and evolve, they will occasionally block Sherlock and\n        # lead to false positives and negatives. Fingerprints should be added\n        # here to filter results that fail to bypass WAFs. Fingerprints should\n        # be highly targetted. Comment at the end of each fingerprint to\n        # indicate target and date fingerprinted.\n        WAFHitMsgs = [\n            r'.loading-spinner{visibility:hidden}body.no-js .challenge-running{display:none}body.dark{background-color:#222;color:#d9d9d9}body.dark a{color:#fff}body.dark a:hover{color:#ee730a;text-decoration:underline}body.dark .lds-ring div{border-color:#999 transparent transparent}body.dark .font-red{color:#b20f03}body.dark', # 2024-05-13 Cloudflare\n            r'<span id=\"challenge-error-text\">', # 2024-11-11 Cloudflare error page\n            r'AwsWafIntegration.forceRefreshToken', # 2024-11-11 Cloudfront (AWS)\n            r'{return l.onPageView}}),Object.defineProperty(r,\"perimeterxIdentifiers\",{enumerable:' # 2024-04-09 PerimeterX / Human Security\n        ]\n\n        if error_text is not None:\n            error_context = error_text\n\n        elif any(hitMsg in r.text for hitMsg in WAFHitMsgs):\n            query_status = QueryStatus.WAF\n\n        else:\n            if any(errtype not in [\"message\", \"status_code\", \"response_url\"] for errtype in error_type):\n                error_context = f\"Unknown error type '{error_type}' for {social_network}\"\n                query_status = QueryStatus.UNKNOWN\n            else:\n                if \"message\" in error_type:\n                    # error_flag True denotes no error found in the HTML\n                    # error_flag False denotes error found in the HTML\n                    error_flag = True\n                    errors = net_info.get(\"errorMsg\")\n                    # errors will hold the error message\n                    # it can be string or list\n                    # by isinstance method we can detect that\n                    # and handle the case for strings as normal procedure\n                    # and if its list we can iterate the errors\n                    if isinstance(errors, str):\n                        # Checks if the error message is in the HTML\n                        # if error is present we will set flag to False\n                        if errors in r.text:\n                            error_flag = False\n                    else:\n                        # If it's list, it will iterate all the error message\n                        for error in errors:\n                            if error in r.text:\n                                error_flag = False\n                                break\n                    if error_flag:\n                        query_status = QueryStatus.CLAIMED\n                    else:\n                        query_status = QueryStatus.AVAILABLE\n\n                if \"status_code\" in error_type and query_status is not QueryStatus.AVAILABLE:\n                    error_codes = net_info.get(\"errorCode\")\n                    query_status = QueryStatus.CLAIMED\n\n                    # Type consistency, allowing for both singlets and lists in manifest\n                    if isinstance(error_codes, int):\n                        error_codes = [error_codes]\n\n                    if error_codes is not None and r.status_code in error_codes:\n                        query_status = QueryStatus.AVAILABLE\n                    elif r.status_code >= 300 or r.status_code < 200:\n                        query_status = QueryStatus.AVAILABLE\n\n                if \"response_url\" in error_type and query_status is not QueryStatus.AVAILABLE:\n                    # For this detection method, we have turned off the redirect.\n                    # So, there is no need to check the response URL: it will always\n                    # match the request.  Instead, we will ensure that the response\n                    # code indicates that the request was successful (i.e. no 404, or\n                    # forward to some odd redirect).\n                    if 200 <= r.status_code < 300:\n                        query_status = QueryStatus.CLAIMED\n                    else:\n                        query_status = QueryStatus.AVAILABLE\n\n        if dump_response:\n            print(\"+++++++++++++++++++++\")\n            print(f\"TARGET NAME   : {social_network}\")\n            print(f\"USERNAME      : {username}\")\n            print(f\"TARGET URL    : {url}\")\n            print(f\"TEST METHOD   : {error_type}\")\n            try:\n                print(f\"STATUS CODES  : {net_info['errorCode']}\")\n            except KeyError:\n                pass\n            print(\"Results...\")\n            try:\n                print(f\"RESPONSE CODE : {r.status_code}\")\n            except Exception:\n                pass\n            try:\n                print(f\"ERROR TEXT    : {net_info['errorMsg']}\")\n            except KeyError:\n                pass\n            print(\">>>>> BEGIN RESPONSE TEXT\")\n            try:\n                print(r.text)\n            except Exception:\n                pass\n            print(\"<<<<< END RESPONSE TEXT\")\n            print(\"VERDICT       : \" + str(query_status))\n            print(\"+++++++++++++++++++++\")\n\n        # Notify caller about results of query.\n        result: QueryResult = QueryResult(\n            username=username,\n            site_name=social_network,\n            site_url_user=url,\n            status=query_status,\n            query_time=response_time,\n            context=error_context,\n        )\n        query_notify.update(result)\n\n        # Save status of request\n        results_site[\"status\"] = result\n\n        # Save results from request\n        results_site[\"http_status\"] = http_status\n        results_site[\"response_text\"] = response_text\n\n        # Add this site's results into final dictionary with all of the other results.\n        results_total[social_network] = results_site\n\n    return results_total",
    "source": "github_repo:sherlock-project/sherlock",
    "file": "sherlock_project/sherlock.py",
    "license": "MIT",
    "language": "python"
}