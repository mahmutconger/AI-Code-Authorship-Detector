{
    "code": "class Configs(MNISTConfigs, SimpleTrainValidConfigs):\n    \"\"\"\n    Configurations with MNIST data and Train & Validation setup\n    \"\"\"\n    epochs: int = 10\n    model: nn.Module = 'capsule_network_model'\n    reconstruction_loss = nn.MSELoss()\n    margin_loss = MarginLoss(n_labels=10)\n    accuracy = AccuracyDirect()\n\n    def init(self):\n        # Print losses and accuracy to screen\n        tracker.set_scalar('loss.*', True)\n        tracker.set_scalar('accuracy.*', True)\n\n        # We need to set the metrics to calculate them for the epoch for training and validation\n        self.state_modules = [self.accuracy]\n\n    def step(self, batch: Any, batch_idx: BatchIndex):\n        \"\"\"\n        This method gets called by the trainer\n        \"\"\"\n        # Set the model mode\n        self.model.train(self.mode.is_train)\n\n        # Get the images and labels and move them to the model's device\n        data, target = batch[0].to(self.device), batch[1].to(self.device)\n\n        # Increment step in training mode\n        if self.mode.is_train:\n            tracker.add_global_step(len(data))\n\n        # Run the model\n        caps, reconstructions, pred = self.model(data)\n\n        # Calculate the total loss\n        loss = self.margin_loss(caps, target) + 0.0005 * self.reconstruction_loss(reconstructions, data)\n        tracker.add(\"loss.\", loss)\n\n        # Call accuracy metric\n        self.accuracy(pred, target)\n\n        if self.mode.is_train:\n            loss.backward()\n\n            self.optimizer.step()\n            # Log parameters and gradients\n            if batch_idx.is_last:\n                tracker.add('model', self.model)\n            self.optimizer.zero_grad()\n\n            tracker.save()",
    "source": "github_repo:labmlai/annotated_deep_learning_paper_implementations",
    "file": "labml_nn/capsule_networks/mnist.py",
    "license": "MIT",
    "language": "python"
}