{
    "code": "class proxy:\n    def __init__(self):\n        self.proxy_list = []\n        self.proxy_filter_list = []\n\n    def get_proxy(self):\n        \"\"\"\n        获取未加工代理列表\n        :return: \n        \"\"\"\n        User_Agent = 'Mozilla/5.0 (Windows NT 6.3; WOW64; rv:43.0) Gecko/20100101 Firefox/43.0'\n        header = dict()\n        header['User-Agent'] = User_Agent\n\n        for i in range(1, 5):\n            time.sleep(1)\n            url = 'http://www.xicidaili.com/nn/' + str(i)\n            res = requests.get(url=url, headers=header).content\n\n            soup = BeautifulSoup(res, \"html.parser\")\n            ips = soup.findAll('tr')\n\n            for x in range(1, len(ips)):\n                ip = ips[x]\n                tds = ip.findAll(\"td\")\n                ip_temp = tds[1].contents[0] + \":\" + tds[2].contents[0]\n                print(ip_temp)\n                self.proxy_list.append(ip_temp)\n\n    def filter_proxy(self):\n        \"\"\"\n        将不可用IP剔除\n        :return: \n        \"\"\"\n        socket.setdefaulttimeout(1)\n        path = os.path.join(os.path.dirname(__file__), './proxy_list')\n        f = open(path, \"w\")\n        head = {\n            'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36',\n            'Connection': 'keep-alive'}\n        url = \"http://icanhazip.com\"\n        proxy_num = 0\n        for proxy in self.proxy_list:\n            proxy_temp = {\"https\": \"https://{}\".format(proxy)}\n            try:\n                req = requests.get(url, proxies=proxy_temp, timeout=2, headers=head).content\n                print(req)\n                write_proxy = proxy + \"\\n\"\n                f.write(write_proxy)\n                proxy_num += 1\n            except Exception:\n                print (\"代理链接超时，去除此IP：{0}\".format(proxy))\n                continue\n        print(\"总共可使用ip量为{}个\".format(proxy_num))\n\n    def get_filter_proxy(self):\n        \"\"\"\n        读取该可用ip文件\n        :return: 可用ip文件list\n        \"\"\"\n        path = os.path.join(os.path.dirname(__file__), './proxy_list')\n        try:\n            with open(path, \"r\", encoding=\"utf-8\") as f:\n                lins = f.readlines()\n                for i in lins:\n                    p = i.strip(\"\\n\")\n                    self.proxy_filter_list.append(p)\n        except Exception:\n            with open(path, \"r\", ) as f:\n                lins = f.readlines()\n                for i in lins:\n                    p = i.strip(\"\\n\")\n                    self.proxy_filter_list.append(p)\n        return self.proxy_filter_list\n\n    def main(self):\n        # self.get_proxy()\n        self.filter_proxy()\n\n    def setProxy(self):\n        \"\"\"\n        开启此功能的时候请确保代理ip是否可用\n        查询的时候设置代理ip,ip设置格式是ip地址+端口，推荐可用的ip代理池：https://github.com/jhao104/proxy_pool\n        :return:\n        \"\"\"\n        ip = self.get_filter_proxy()\n        setIp = ip[random.randint(0, len(ip) - 1)]\n        proxie = {\n            'http': 'http://{}'.format(setIp),\n            'https': 'http://{}'.format(setIp),\n        }\n        return proxie",
    "source": "github_repo:testerSunshine/12306",
    "file": "agency/agency_tools.py",
    "license": "MIT",
    "language": "python"
}