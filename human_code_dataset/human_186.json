{
    "code": "class __ModuleName__VectorStore(VectorStore):\n    # TODO: Replace all TODOs in docstring.\n    \"\"\"__ModuleName__ vector store integration.\n\n    # TODO: Replace with relevant packages, env vars.\n    Setup:\n        Install `__package_name__` and set environment variable `__MODULE_NAME___API_KEY`.\n\n        ```bash\n        pip install -U __package_name__\n        export __MODULE_NAME___API_KEY=\"your-api-key\"\n        ```\n\n    # TODO: Populate with relevant params.\n    Key init args — indexing params:\n        collection_name:\n            Name of the collection.\n        embedding_function:\n            Embedding function to use.\n\n    # TODO: Populate with relevant params.\n    Key init args — client params:\n        client:\n            Client to use.\n        connection_args:\n            Connection arguments.\n\n    # TODO: Replace with relevant init params.\n    Instantiate:\n        ```python\n        from __module_name__.vectorstores import __ModuleName__VectorStore\n        from langchain_openai import OpenAIEmbeddings\n\n        vector_store = __ModuleName__VectorStore(\n            collection_name=\"foo\",\n            embedding_function=OpenAIEmbeddings(),\n            connection_args={\"uri\": \"./foo.db\"},\n            # other params...\n        )\n        ```\n\n    # TODO: Populate with relevant variables.\n    Add Documents:\n        ```python\n        from langchain_core.documents import Document\n\n        document_1 = Document(page_content=\"foo\", metadata={\"baz\": \"bar\"})\n        document_2 = Document(page_content=\"thud\", metadata={\"bar\": \"baz\"})\n        document_3 = Document(page_content=\"i will be deleted :(\")\n\n        documents = [document_1, document_2, document_3]\n        ids = [\"1\", \"2\", \"3\"]\n        vector_store.add_documents(documents=documents, ids=ids)\n        ```\n\n    # TODO: Populate with relevant variables.\n    Delete Documents:\n        ```python\n        vector_store.delete(ids=[\"3\"])\n        ```\n\n    # TODO: Fill out with relevant variables and example output.\n    Search:\n        ```python\n        results = vector_store.similarity_search(query=\"thud\",k=1)\n        for doc in results:\n            print(f\"* {doc.page_content} [{doc.metadata}]\")\n        ```\n\n        ```python\n        # TODO: Example output\n        ```\n\n    # TODO: Fill out with relevant variables and example output.\n    Search with filter:\n        ```python\n        results = vector_store.similarity_search(query=\"thud\",k=1,filter={\"bar\": \"baz\"})\n        for doc in results:\n            print(f\"* {doc.page_content} [{doc.metadata}]\")\n        ```\n\n        ```python\n        # TODO: Example output\n        ```\n\n    # TODO: Fill out with relevant variables and example output.\n    Search with score:\n        ```python\n        results = vector_store.similarity_search_with_score(query=\"qux\",k=1)\n        for doc, score in results:\n            print(f\"* [SIM={score:3f}] {doc.page_content} [{doc.metadata}]\")\n        ```\n\n        ```python\n        # TODO: Example output\n        ```\n\n    # TODO: Fill out with relevant variables and example output.\n    Async:\n        ```python\n        # add documents\n        # await vector_store.aadd_documents(documents=documents, ids=ids)\n\n        # delete documents\n        # await vector_store.adelete(ids=[\"3\"])\n\n        # search\n        # results = vector_store.asimilarity_search(query=\"thud\",k=1)\n\n        # search with score\n        results = await vector_store.asimilarity_search_with_score(query=\"qux\",k=1)\n        for doc,score in results:\n            print(f\"* [SIM={score:3f}] {doc.page_content} [{doc.metadata}]\")\n        ```\n\n        ```python\n        # TODO: Example output\n        ```\n\n    # TODO: Fill out with relevant variables and example output.\n    Use as Retriever:\n        ```python\n        retriever = vector_store.as_retriever(\n            search_type=\"mmr\",\n            search_kwargs={\"k\": 1, \"fetch_k\": 2, \"lambda_mult\": 0.5},\n        )\n        retriever.invoke(\"thud\")\n        ```\n\n        ```python\n        # TODO: Example output\n\n        ```\n    \"\"\"  # noqa: E501\n\n    def __init__(self, embedding: Embeddings) -> None:\n        \"\"\"Initialize with the given embedding function.\n\n        Args:\n            embedding: embedding function to use.\n        \"\"\"\n        self._database: dict[str, dict[str, Any]] = {}\n        self.embedding = embedding\n\n    @classmethod\n    def from_texts(\n        cls: Type[__ModuleName__VectorStore],\n        texts: List[str],\n        embedding: Embeddings,\n        metadatas: list[dict] | None = None,\n        **kwargs: Any,\n    ) -> __ModuleName__VectorStore:\n        store = cls(\n            embedding=embedding,\n        )\n        store.add_texts(texts=texts, metadatas=metadatas, **kwargs)\n        return store\n\n    # optional: add custom async implementations\n    # @classmethod\n    # async def afrom_texts(\n    #     cls: Type[VST],\n    #     texts: List[str],\n    #     embedding: Embeddings,\n    #     metadatas: list[dict] | None = None,\n    #     **kwargs: Any,\n    # ) -> VST:\n    #     return await asyncio.get_running_loop().run_in_executor(\n    #         None, partial(cls.from_texts, **kwargs), texts, embedding, metadatas\n    #     )\n\n    @property\n    def embeddings(self) -> Embeddings:\n        return self.embedding\n\n    def add_documents(\n        self,\n        documents: List[Document],\n        ids: list[str] | None = None,\n        **kwargs: Any,\n    ) -> List[str]:\n        \"\"\"Add documents to the store.\"\"\"\n        texts = [doc.page_content for doc in documents]\n        vectors = self.embedding.embed_documents(texts)\n\n        if ids and len(ids) != len(texts):\n            msg = (\n                f\"ids must be the same length as texts. \"\n                f\"Got {len(ids)} ids and {len(texts)} texts.\"\n            )\n            raise ValueError(msg)\n\n        id_iterator: Iterator[str | None] = (\n            iter(ids) if ids else iter(doc.id for doc in documents)\n        )\n\n        ids_ = []\n\n        for doc, vector in zip(documents, vectors):\n            doc_id = next(id_iterator)\n            doc_id_ = doc_id if doc_id else str(uuid.uuid4())\n            ids_.append(doc_id_)\n            self._database[doc_id_] = {\n                \"id\": doc_id_,\n                \"vector\": vector,\n                \"text\": doc.page_content,\n                \"metadata\": doc.metadata,\n            }\n\n        return ids_\n\n    # optional: add custom async implementations\n    # async def aadd_documents(\n    #     self,\n    #     documents: List[Document],\n    #     ids: list[str] | None = None,\n    #     **kwargs: Any,\n    # ) -> List[str]:\n    #     raise NotImplementedError\n\n    def delete(self, ids: list[str] | None = None, **kwargs: Any) -> None:\n        if ids:\n            for _id in ids:\n                self._database.pop(_id, None)\n\n    # optional: add custom async implementations\n    # async def adelete(\n    #     self, ids: list[str] | None = None, **kwargs: Any\n    # ) -> None:\n    #     raise NotImplementedError\n\n    def get_by_ids(self, ids: Sequence[str], /) -> list[Document]:\n        \"\"\"Get documents by their ids.\n\n        Args:\n            ids: The ids of the documents to get.\n\n        Returns:\n            A list of Document objects.\n        \"\"\"\n        documents = []\n\n        for doc_id in ids:\n            doc = self._database.get(doc_id)\n            if doc:\n                documents.append(\n                    Document(\n                        id=doc[\"id\"],\n                        page_content=doc[\"text\"],\n                        metadata=doc[\"metadata\"],\n                    )\n                )\n        return documents\n\n    # optional: add custom async implementations\n    # async def aget_by_ids(self, ids: Sequence[str], /) -> list[Document]:\n    #     raise NotImplementedError\n\n    # NOTE: the below helper method implements similarity search for in-memory\n    # storage. It is optional and not a part of the vector store interface.\n    def _similarity_search_with_score_by_vector(\n        self,\n        embedding: List[float],\n        k: int = 4,\n        filter: Callable[[Document], bool] | None = None,\n        **kwargs: Any,\n    ) -> List[tuple[Document, float, List[float]]]:\n        # get all docs with fixed order in list\n        docs = list(self._database.values())\n\n        if filter is not None:\n            docs = [\n                doc\n                for doc in docs\n                if filter(Document(page_content=doc[\"text\"], metadata=doc[\"metadata\"]))\n            ]\n\n        if not docs:\n            return []\n\n        similarity = cosine_similarity([embedding], [doc[\"vector\"] for doc in docs])[0]\n\n        # get the indices ordered by similarity score\n        top_k_idx = similarity.argsort()[::-1][:k]\n\n        return [\n            (\n                # Document\n                Document(\n                    id=doc_dict[\"id\"],\n                    page_content=doc_dict[\"text\"],\n                    metadata=doc_dict[\"metadata\"],\n                ),\n                # Score\n                float(similarity[idx].item()),\n                # Embedding vector\n                doc_dict[\"vector\"],\n            )\n            for idx in top_k_idx\n            # Assign using walrus operator to avoid multiple lookups\n            if (doc_dict := docs[idx])\n        ]\n\n    def similarity_search(\n        self, query: str, k: int = 4, **kwargs: Any\n    ) -> List[Document]:\n        embedding = self.embedding.embed_query(query)\n        return [\n            doc\n            for doc, _, _ in self._similarity_search_with_score_by_vector(\n                embedding=embedding, k=k, **kwargs\n            )\n        ]\n\n    # optional: add custom async implementations\n    # async def asimilarity_search(\n    #     self, query: str, k: int = 4, **kwargs: Any\n    # ) -> List[Document]:\n    #     # This is a temporary workaround to make the similarity search\n    #     # asynchronous. The proper solution is to make the similarity search\n    #     # asynchronous in the vector store implementations.\n    #     func = partial(self.similarity_search, query, k=k, **kwargs)\n    #     return await asyncio.get_event_loop().run_in_executor(None, func)\n\n    def similarity_search_with_score(\n        self, query: str, k: int = 4, **kwargs: Any\n    ) -> List[Tuple[Document, float]]:\n        embedding = self.embedding.embed_query(query)\n        return [\n            (doc, similarity)\n            for doc, similarity, _ in self._similarity_search_with_score_by_vector(\n                embedding=embedding, k=k, **kwargs\n            )\n        ]",
    "source": "github_repo:langchain-ai/langchain",
    "file": "libs/cli/langchain_cli/integration_template/integration_template/vectorstores.py",
    "license": "MIT",
    "language": "python"
}