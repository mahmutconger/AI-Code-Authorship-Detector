{
    "code": "class Text2SemanticDataset(Dataset):\n    \"\"\"dataset class for text tokens to semantic model training.\"\"\"\n\n    def __init__(\n        self,\n        phoneme_path: str,\n        semantic_path: str,\n        max_sample: int = None,\n        max_sec: int = 100,\n        pad_val: int = 1024,\n        # min value of phoneme/sec\n        min_ps_ratio: int = 3,\n        # max value of phoneme/sec\n        max_ps_ratio: int = 25,\n    ) -> None:\n        super().__init__()\n\n        self.semantic_data = pd.read_csv(\n            semantic_path,\n            delimiter=\"\\t\",\n            encoding=\"utf-8\",\n        )\n        # get dict\n        self.path2 = phoneme_path  # \"%s/2-name2text.txt\"%exp_dir#phoneme_path\n        self.path3 = \"%s/3-bert\" % (\n            os.path.dirname(\n                phoneme_path,\n            )\n        )  # \"%s/3-bert\"%exp_dir#bert_dir\n        self.path6 = semantic_path  # \"%s/6-name2semantic.tsv\"%exp_dir#semantic_path\n        assert os.path.exists(self.path2)\n        assert os.path.exists(self.path6)\n        self.phoneme_data = {}\n        with open(self.path2, \"r\", encoding=\"utf8\") as f:\n            lines = f.read().strip(\"\\n\").split(\"\\n\")\n\n        for line in lines:\n            tmp = line.split(\"\\t\")\n            if len(tmp) != 4:\n                continue\n            self.phoneme_data[tmp[0]] = [tmp[1], tmp[2], tmp[3]]\n\n        # self.phoneme_data = np.load(phoneme_path, allow_pickle=True).item()\n        # pad for semantic tokens\n        self.PAD: int = pad_val\n        # self.hz = 25\n        # with open(\"/data/docker/liujing04/gpt-vits/mq-vits-s1bert_no_bert/configs/s2.json\", \"r\") as f:data = f.read()\n        # data=json.loads(data)[\"model\"][\"semantic_frame_rate\"]#50hz\n        # self.hz=int(data[:-2])#\n        self.hz = int(os.environ.get(\"hz\", \"25hz\")[:-2])\n\n        # max seconds of semantic token\n        self.max_sec = max_sec\n        self.min_ps_ratio = min_ps_ratio\n        self.max_ps_ratio = max_ps_ratio\n\n        if max_sample is not None:\n            self.semantic_data = self.semantic_data[:max_sample]\n\n        # {idx: (semantic, phoneme)}\n        # semantic list, phoneme list\n        self.semantic_phoneme = []\n        self.item_names = []\n\n        self.inited = False\n\n        if not self.inited:\n            # 调用初始化函数\n            self.init_batch()\n            self.inited = True\n            del self.semantic_data\n            del self.phoneme_data\n        # self.tokenizer = AutoTokenizer.from_pretrained(\"hfl/chinese-roberta-wwm-ext-large\")\n        # self.tokenizer = AutoTokenizer.from_pretrained(\"/data/docker/liujing04/bert-vits2/Bert-VITS2-master20231106/bert/chinese-roberta-wwm-ext-large\")\n\n    def init_batch(self):\n        semantic_data_len = len(self.semantic_data)\n        phoneme_data_len = len(self.phoneme_data.keys())\n        print(\"semantic_data_len:\", semantic_data_len)\n        print(\"phoneme_data_len:\", phoneme_data_len)\n        print(self.semantic_data)\n        idx = 0\n        num_not_in = 0\n        num_deleted_bigger = 0\n        num_deleted_ps = 0\n        for i in range(semantic_data_len):\n            # 先依次遍历\n            # get str\n            item_name = self.semantic_data.iloc[i, 0]\n            # print(self.phoneme_data)\n            try:\n                phoneme, word2ph, text = self.phoneme_data[item_name]\n            except Exception:\n                traceback.print_exc()\n                # print(f\"{item_name} not in self.phoneme_data !\")\n                num_not_in += 1\n                continue\n\n            semantic_str = self.semantic_data.iloc[i, 1]\n            # get token list\n            semantic_ids = [int(idx) for idx in semantic_str.split(\" \")]\n            # (T), 是否需要变成 (1, T) -> 不需要，因为需要求 len\n            # 过滤掉太长的样本\n            if (\n                len(semantic_ids) > self.max_sec * self.hz\n            ):  #########1###根据token个数推测总时长过滤时长60s（config里）#40*25=1k\n                num_deleted_bigger += 1\n                continue\n            # (T, ), 这个速度不会很慢，所以可以在一开始就处理，无需在 __getitem__ 里面单个处理####\n            phoneme = phoneme.split(\" \")\n\n            try:\n                phoneme_ids = cleaned_text_to_sequence(phoneme, version)\n            except:\n                traceback.print_exc()\n                # print(f\"{item_name} not in self.phoneme_data !\")\n                num_not_in += 1\n                continue\n            # if len(phoneme_ids) >400:###########2：改为恒定限制为semantic/2.5就行\n            if len(phoneme_ids) > self.max_sec * self.hz / 2.5:  ###########2：改为恒定限制为semantic/2.5就行\n                num_deleted_ps += 1\n                continue\n            # if len(semantic_ids) > 1000:###########3\n            #     num_deleted_bigger += 1\n            #     continue\n\n            ps_ratio = len(phoneme_ids) / (len(semantic_ids) / self.hz)\n\n            if ps_ratio > self.max_ps_ratio or ps_ratio < self.min_ps_ratio:  ##########4#3~25#每秒多少个phone\n                num_deleted_ps += 1\n                # print(item_name)\n                continue\n\n            self.semantic_phoneme.append((semantic_ids, phoneme_ids))\n            idx += 1\n            self.item_names.append(item_name)\n\n        min_num = 100  # 20直接不补#30补了也不存ckpt\n        leng = len(self.semantic_phoneme)\n        if leng < min_num:\n            tmp1 = self.semantic_phoneme\n            tmp2 = self.item_names\n            self.semantic_phoneme = []\n            self.item_names = []\n            for _ in range(max(2, int(min_num / leng))):\n                self.semantic_phoneme += tmp1\n                self.item_names += tmp2\n        if num_not_in > 0:\n            print(f\"there are {num_not_in} semantic datas not in phoneme datas\")\n        if num_deleted_bigger > 0:\n            print(\n                f\"deleted {num_deleted_bigger} audios who's duration are bigger than {self.max_sec} seconds\",\n            )\n        if num_deleted_ps > 0:\n            # 4702 for LibriTTS, LirbriTTS 是标注数据, 是否需要筛？=> 需要，有值为 100 的极端值\n            print(\n                f\"deleted {num_deleted_ps} audios who's phoneme/sec are bigger than {self.max_ps_ratio} or smaller than {self.min_ps_ratio}\",\n            )\n        \"\"\"\n        there are 31 semantic datas not in phoneme datas\n        deleted 34 audios who's duration are bigger than 54 seconds\n        deleted 3190 audios who's phoneme/sec are bigger than 25 or smaller than 3\n        dataset.__len__(): 366463\n\n        \"\"\"\n        # 345410 for LibriTTS\n        print(\"dataset.__len__():\", self.__len__())\n\n    def __get_item_names__(self) -> List[str]:\n        return self.item_names\n\n    def __len__(self) -> int:\n        return len(self.semantic_phoneme)\n\n    def __getitem__(self, idx: int) -> Dict:\n        semantic_ids, phoneme_ids = self.semantic_phoneme[idx]\n        item_name = self.item_names[idx]\n        phoneme_ids_len = len(phoneme_ids)\n        # semantic tokens target\n        semantic_ids_len = len(semantic_ids)\n\n        flag = 0\n        path_bert = \"%s/%s.pt\" % (self.path3, item_name)\n        if os.path.exists(path_bert) == True:\n            bert_feature = torch.load(path_bert, map_location=\"cpu\")\n        else:\n            flag = 1\n        if flag == 1:\n            # bert_feature=torch.zeros_like(phoneme_ids,dtype=torch.float32)\n            bert_feature = None\n        else:\n            assert bert_feature.shape[-1] == len(phoneme_ids)\n        return {\n            \"idx\": idx,\n            \"phoneme_ids\": phoneme_ids,\n            \"phoneme_ids_len\": phoneme_ids_len,\n            \"semantic_ids\": semantic_ids,\n            \"semantic_ids_len\": semantic_ids_len,\n            \"bert_feature\": bert_feature,\n        }\n\n    def get_sample_length(self, idx: int):\n        semantic_ids = self.semantic_phoneme[idx][0]\n        sec = 1.0 * len(semantic_ids) / self.hz\n        return sec\n\n    def collate(self, examples: List[Dict]) -> Dict:\n        sample_index: List[int] = []\n        phoneme_ids: List[torch.Tensor] = []\n        phoneme_ids_lens: List[int] = []\n        semantic_ids: List[torch.Tensor] = []\n        semantic_ids_lens: List[int] = []\n        # return\n\n        for item in examples:\n            sample_index.append(item[\"idx\"])\n            phoneme_ids.append(np.array(item[\"phoneme_ids\"], dtype=np.int64))\n            semantic_ids.append(np.array(item[\"semantic_ids\"], dtype=np.int64))\n            phoneme_ids_lens.append(item[\"phoneme_ids_len\"])\n            semantic_ids_lens.append(item[\"semantic_ids_len\"])\n\n        # pad 0\n        phoneme_ids = batch_sequences(phoneme_ids)\n        semantic_ids = batch_sequences(semantic_ids, pad_value=self.PAD)\n\n        # # convert each batch to torch.tensor\n        phoneme_ids = torch.tensor(phoneme_ids)\n        semantic_ids = torch.tensor(semantic_ids)\n        phoneme_ids_lens = torch.tensor(phoneme_ids_lens)\n        semantic_ids_lens = torch.tensor(semantic_ids_lens)\n        bert_padded = torch.FloatTensor(len(examples), 1024, max(phoneme_ids_lens))\n        bert_padded.zero_()\n\n        for idx, item in enumerate(examples):\n            bert = item[\"bert_feature\"]\n            if bert != None:\n                bert_padded[idx, :, : bert.shape[-1]] = bert\n\n        return {\n            # List[int]\n            \"ids\": sample_index,\n            # torch.Tensor (B, max_phoneme_length)\n            \"phoneme_ids\": phoneme_ids,\n            # torch.Tensor (B)\n            \"phoneme_ids_len\": phoneme_ids_lens,\n            # torch.Tensor (B, max_semantic_ids_length)\n            \"semantic_ids\": semantic_ids,\n            # torch.Tensor (B)\n            \"semantic_ids_len\": semantic_ids_lens,\n            # torch.Tensor (B, 1024, max_phoneme_length)\n            \"bert_feature\": bert_padded,\n        }",
    "source": "github_repo:RVC-Boss/GPT-SoVITS",
    "file": "GPT_SoVITS/AR/data/dataset.py",
    "license": "MIT",
    "language": "python"
}