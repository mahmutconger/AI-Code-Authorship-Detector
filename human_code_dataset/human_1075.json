{
    "code": "def __init__(self, config, norm_first=False, top_k=3):\n        super(Text2SemanticDecoder, self).__init__()\n        self.model_dim = config[\"model\"][\"hidden_dim\"]\n        self.embedding_dim = config[\"model\"][\"embedding_dim\"]\n        self.num_head = config[\"model\"][\"head\"]\n        self.num_layers = config[\"model\"][\"n_layer\"]\n        self.norm_first = norm_first\n        self.vocab_size = config[\"model\"][\"vocab_size\"]\n        self.phoneme_vocab_size = config[\"model\"][\"phoneme_vocab_size\"]\n        self.p_dropout = config[\"model\"][\"dropout\"]\n        self.EOS = config[\"model\"][\"EOS\"]\n        self.norm_first = norm_first\n        assert self.EOS == self.vocab_size - 1\n        # should be same as num of kmeans bin\n        # assert self.EOS == 1024\n        self.bert_proj = nn.Linear(1024, self.embedding_dim)\n        self.ar_text_embedding = TokenEmbedding(\n            self.embedding_dim,\n            self.phoneme_vocab_size,\n            self.p_dropout,\n        )\n        self.ar_text_position = SinePositionalEmbedding(\n            self.embedding_dim,\n            dropout=0.1,\n            scale=False,\n            alpha=True,\n        )\n        self.ar_audio_embedding = TokenEmbedding(\n            self.embedding_dim,\n            self.vocab_size,\n            self.p_dropout,\n        )\n        self.ar_audio_position = SinePositionalEmbedding(\n            self.embedding_dim,\n            dropout=0.1,\n            scale=False,\n            alpha=True,\n        )\n\n        self.h = TransformerEncoder(\n            TransformerEncoderLayer(\n                d_model=self.model_dim,\n                nhead=self.num_head,\n                dim_feedforward=self.model_dim * 4,\n                dropout=0.1,\n                batch_first=True,\n                norm_first=norm_first,\n            ),\n            num_layers=self.num_layers,\n            norm=LayerNorm(self.model_dim) if norm_first else None,\n        )\n\n        self.ar_predict_layer = nn.Linear(self.model_dim, self.vocab_size, bias=False)\n        self.loss_fct = nn.CrossEntropyLoss(reduction=\"sum\")\n\n        self.ar_accuracy_metric = MulticlassAccuracy(\n            self.vocab_size,\n            top_k=top_k,\n            average=\"micro\",\n            multidim_average=\"global\",\n            ignore_index=self.EOS,\n        )\n\n        blocks = []\n\n        for i in range(self.num_layers):\n            layer = self.h.layers[i]\n            t2smlp = T2SMLP(\n                layer.linear1.weight,\n                layer.linear1.bias,\n                layer.linear2.weight,\n                layer.linear2.bias,\n            )\n\n            block = T2SBlock(\n                self.num_head,\n                self.model_dim,\n                t2smlp,\n                layer.self_attn.in_proj_weight,\n                layer.self_attn.in_proj_bias,\n                layer.self_attn.out_proj.weight,\n                layer.self_attn.out_proj.bias,\n                layer.norm1.weight,\n                layer.norm1.bias,\n                layer.norm1.eps,\n                layer.norm2.weight,\n                layer.norm2.bias,\n                layer.norm2.eps,\n            )\n\n            blocks.append(block)\n\n        self.t2s_transformer = T2STransformer(self.num_layers, blocks)",
    "source": "github_repo:RVC-Boss/GPT-SoVITS",
    "file": "GPT_SoVITS/AR/models/t2s_model.py",
    "license": "MIT",
    "language": "python"
}