{
    "code": "class LatentFinetuneDiffusion(LatentDiffusion):\n    \"\"\"\n         Basis for different finetunas, such as inpainting or depth2image\n         To disable finetuning mode, set finetune_keys to None\n    \"\"\"\n\n    def __init__(self,\n                 concat_keys: tuple,\n                 finetune_keys=(\"model.diffusion_model.input_blocks.0.0.weight\",\n                                \"model_ema.diffusion_modelinput_blocks00weight\"\n                                ),\n                 keep_finetune_dims=4,\n                 # if model was trained without concat mode before and we would like to keep these channels\n                 c_concat_log_start=None,  # to log reconstruction of c_concat codes\n                 c_concat_log_end=None,\n                 *args, **kwargs\n                 ):\n        ckpt_path = kwargs.pop(\"ckpt_path\", None)\n        ignore_keys = kwargs.pop(\"ignore_keys\", list())\n        super().__init__(*args, **kwargs)\n        self.finetune_keys = finetune_keys\n        self.concat_keys = concat_keys\n        self.keep_dims = keep_finetune_dims\n        self.c_concat_log_start = c_concat_log_start\n        self.c_concat_log_end = c_concat_log_end\n        if exists(self.finetune_keys): assert exists(ckpt_path), 'can only finetune from a given checkpoint'\n        if exists(ckpt_path):\n            self.init_from_ckpt(ckpt_path, ignore_keys)\n\n    def init_from_ckpt(self, path, ignore_keys=list(), only_model=False):\n        sd = torch.load(path, map_location=\"cpu\")\n        if \"state_dict\" in list(sd.keys()):\n            sd = sd[\"state_dict\"]\n        keys = list(sd.keys())\n        for k in keys:\n            for ik in ignore_keys:\n                if k.startswith(ik):\n                    print(\"Deleting key {} from state_dict.\".format(k))\n                    del sd[k]\n\n            # make it explicit, finetune by including extra input channels\n            if exists(self.finetune_keys) and k in self.finetune_keys:\n                new_entry = None\n                for name, param in self.named_parameters():\n                    if name in self.finetune_keys:\n                        print(\n                            f\"modifying key '{name}' and keeping its original {self.keep_dims} (channels) dimensions only\")\n                        new_entry = torch.zeros_like(param)  # zero init\n                assert exists(new_entry), 'did not find matching parameter to modify'\n                new_entry[:, :self.keep_dims, ...] = sd[k]\n                sd[k] = new_entry\n\n        missing, unexpected = self.load_state_dict(sd, strict=False) if not only_model else self.model.load_state_dict(\n            sd, strict=False)\n        print(f\"Restored from {path} with {len(missing)} missing and {len(unexpected)} unexpected keys\")\n        if len(missing) > 0:\n            print(f\"Missing Keys: {missing}\")\n        if len(unexpected) > 0:\n            print(f\"Unexpected Keys: {unexpected}\")\n\n    @torch.no_grad()\n    def log_images(self, batch, N=8, n_row=4, sample=True, ddim_steps=200, ddim_eta=1., return_keys=None,\n                   quantize_denoised=True, inpaint=True, plot_denoise_rows=False, plot_progressive_rows=True,\n                   plot_diffusion_rows=True, unconditional_guidance_scale=1., unconditional_guidance_label=None,\n                   use_ema_scope=True,\n                   **kwargs):\n        ema_scope = self.ema_scope if use_ema_scope else nullcontext\n        use_ddim = ddim_steps is not None\n\n        log = dict()\n        z, c, x, xrec, xc = self.get_input(batch, self.first_stage_key, bs=N, return_first_stage_outputs=True)\n        c_cat, c = c[\"c_concat\"][0], c[\"c_crossattn\"][0]\n        N = min(x.shape[0], N)\n        n_row = min(x.shape[0], n_row)\n        log[\"inputs\"] = x\n        log[\"reconstruction\"] = xrec\n        if self.model.conditioning_key is not None:\n            if hasattr(self.cond_stage_model, \"decode\"):\n                xc = self.cond_stage_model.decode(c)\n                log[\"conditioning\"] = xc\n            elif self.cond_stage_key in [\"caption\", \"txt\"]:\n                xc = log_txt_as_img((x.shape[2], x.shape[3]), batch[self.cond_stage_key], size=x.shape[2] // 25)\n                log[\"conditioning\"] = xc\n            elif self.cond_stage_key in ['class_label', 'cls']:\n                xc = log_txt_as_img((x.shape[2], x.shape[3]), batch[\"human_label\"], size=x.shape[2] // 25)\n                log['conditioning'] = xc\n            elif isimage(xc):\n                log[\"conditioning\"] = xc\n            if ismap(xc):\n                log[\"original_conditioning\"] = self.to_rgb(xc)\n\n        if not (self.c_concat_log_start is None and self.c_concat_log_end is None):\n            log[\"c_concat_decoded\"] = self.decode_first_stage(c_cat[:, self.c_concat_log_start:self.c_concat_log_end])\n\n        if plot_diffusion_rows:\n            # get diffusion row\n            diffusion_row = list()\n            z_start = z[:n_row]\n            for t in range(self.num_timesteps):\n                if t % self.log_every_t == 0 or t == self.num_timesteps - 1:\n                    t = repeat(torch.tensor([t]), '1 -> b', b=n_row)\n                    t = t.to(self.device).long()\n                    noise = torch.randn_like(z_start)\n                    z_noisy = self.q_sample(x_start=z_start, t=t, noise=noise)\n                    diffusion_row.append(self.decode_first_stage(z_noisy))\n\n            diffusion_row = torch.stack(diffusion_row)  # n_log_step, n_row, C, H, W\n            diffusion_grid = rearrange(diffusion_row, 'n b c h w -> b n c h w')\n            diffusion_grid = rearrange(diffusion_grid, 'b n c h w -> (b n) c h w')\n            diffusion_grid = make_grid(diffusion_grid, nrow=diffusion_row.shape[0])\n            log[\"diffusion_row\"] = diffusion_grid\n\n        if sample:\n            # get denoise row\n            with ema_scope(\"Sampling\"):\n                samples, z_denoise_row = self.sample_log(cond={\"c_concat\": [c_cat], \"c_crossattn\": [c]},\n                                                         batch_size=N, ddim=use_ddim,\n                                                         ddim_steps=ddim_steps, eta=ddim_eta)\n                # samples, z_denoise_row = self.sample(cond=c, batch_size=N, return_intermediates=True)\n            x_samples = self.decode_first_stage(samples)\n            log[\"samples\"] = x_samples\n            if plot_denoise_rows:\n                denoise_grid = self._get_denoise_row_from_list(z_denoise_row)\n                log[\"denoise_row\"] = denoise_grid\n\n        if unconditional_guidance_scale > 1.0:\n            uc_cross = self.get_unconditional_conditioning(N, unconditional_guidance_label)\n            uc_cat = c_cat\n            uc_full = {\"c_concat\": [uc_cat], \"c_crossattn\": [uc_cross]}\n            with ema_scope(\"Sampling with classifier-free guidance\"):\n                samples_cfg, _ = self.sample_log(cond={\"c_concat\": [c_cat], \"c_crossattn\": [c]},\n                                                 batch_size=N, ddim=use_ddim,\n                                                 ddim_steps=ddim_steps, eta=ddim_eta,\n                                                 unconditional_guidance_scale=unconditional_guidance_scale,\n                                                 unconditional_conditioning=uc_full,\n                                                 )\n                x_samples_cfg = self.decode_first_stage(samples_cfg)\n                log[f\"samples_cfg_scale_{unconditional_guidance_scale:.2f}\"] = x_samples_cfg\n\n        return log",
    "source": "github_repo:Stability-AI/stablediffusion",
    "file": "ldm/models/diffusion/ddpm.py",
    "license": "MIT",
    "language": "python"
}