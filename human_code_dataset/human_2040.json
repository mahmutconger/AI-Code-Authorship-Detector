{
    "code": "def __init__(\n        self,\n        hidden_channels,\n        filter_channels,\n        n_heads,\n        n_layers,\n        kernel_size=1,\n        p_dropout=0.0,\n        proximal_bias=False,\n        proximal_init=True,\n        **kwargs\n    ):\n        super().__init__()\n        self.hidden_channels = hidden_channels\n        self.filter_channels = filter_channels\n        self.n_heads = n_heads\n        self.n_layers = n_layers\n        self.kernel_size = kernel_size\n        self.p_dropout = p_dropout\n        self.proximal_bias = proximal_bias\n        self.proximal_init = proximal_init\n\n        self.drop = nn.Dropout(p_dropout)\n        self.self_attn_layers = nn.ModuleList()\n        self.norm_layers_0 = nn.ModuleList()\n        self.encdec_attn_layers = nn.ModuleList()\n        self.norm_layers_1 = nn.ModuleList()\n        self.ffn_layers = nn.ModuleList()\n        self.norm_layers_2 = nn.ModuleList()\n        for i in range(self.n_layers):\n            self.self_attn_layers.append(\n                MultiHeadAttention(\n                    hidden_channels,\n                    hidden_channels,\n                    n_heads,\n                    p_dropout=p_dropout,\n                    proximal_bias=proximal_bias,\n                    proximal_init=proximal_init,\n                )\n            )\n            self.norm_layers_0.append(LayerNorm(hidden_channels))\n            self.encdec_attn_layers.append(\n                MultiHeadAttention(\n                    hidden_channels, hidden_channels, n_heads, p_dropout=p_dropout\n                )\n            )\n            self.norm_layers_1.append(LayerNorm(hidden_channels))\n            self.ffn_layers.append(\n                FFN(\n                    hidden_channels,\n                    hidden_channels,\n                    filter_channels,\n                    kernel_size,\n                    p_dropout=p_dropout,\n                    causal=True,\n                )\n            )\n            self.norm_layers_2.append(LayerNorm(hidden_channels))",
    "source": "github_repo:myshell-ai/OpenVoice",
    "file": "openvoice/attentions.py",
    "license": "MIT",
    "language": "python"
}