{
    "code": "def __init__(self):\n        super().__init__()\n        # First convolution layer has $256$, $9 \\times 9$ convolution kernels\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=256, kernel_size=9, stride=1)\n        # The second layer (Primary Capsules) s a convolutional capsule layer with $32$ channels\n        # of convolutional $8D$ capsules ($8$ features per capsule).\n        # That is, each primary capsule contains 8 convolutional units with a 9 Ã— 9 kernel and a stride of 2.\n        # In order to implement this we create a convolutional layer with $32 \\times 8$ channels and\n        # reshape and permutate its output to get the capsules of $8$ features each.\n        self.conv2 = nn.Conv2d(in_channels=256, out_channels=32 * 8, kernel_size=9, stride=2, padding=0)\n        self.squash = Squash()\n\n        # Routing layer gets the $32 \\times 6 \\times 6$ primary capsules and produces $10$ capsules.\n        # Each of the primary capsules have $8$ features, while output capsules (Digit Capsules)\n        # have $16$ features.\n        # The routing algorithm iterates $3$ times.\n        self.digit_capsules = Router(32 * 6 * 6, 10, 8, 16, 3)\n\n        # This is the decoder mentioned in the paper.\n        # It takes the outputs of the $10$ digit capsules, each with $16$ features to reproduce the\n        # image. It goes through linear layers of sizes $512$ and $1024$ with $ReLU$ activations.\n        self.decoder = nn.Sequential(\n            nn.Linear(16 * 10, 512),\n            nn.ReLU(),\n            nn.Linear(512, 1024),\n            nn.ReLU(),\n            nn.Linear(1024, 784),\n            nn.Sigmoid()\n        )",
    "source": "github_repo:labmlai/annotated_deep_learning_paper_implementations",
    "file": "labml_nn/capsule_networks/mnist.py",
    "license": "MIT",
    "language": "python"
}