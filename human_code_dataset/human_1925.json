{
    "code": "def heatmap_and_track(\n    source_weights_path: str,\n    source_video_path: str,\n    target_video_path: str,\n    confidence_threshold: float = 0.35,\n    iou_threshold: float = 0.5,\n    heatmap_alpha: float = 0.5,\n    radius: int = 25,\n    track_activation_threshold: float = 0.35,\n    track_seconds: int = 5,\n    minimum_matching_threshold: float = 0.99,\n) -> None:\n    ### instantiate model\n    model = YOLO(source_weights_path)\n\n    ### heatmap config\n    heat_map_annotator = sv.HeatMapAnnotator(\n        position=sv.Position.BOTTOM_CENTER,\n        opacity=heatmap_alpha,\n        radius=radius,\n        kernel_size=25,\n        top_hue=0,\n        low_hue=125,\n    )\n\n    ### annotation config\n    label_annotator = sv.LabelAnnotator(text_position=sv.Position.CENTER)\n\n    ### get the video fps\n    cap = cv2.VideoCapture(source_video_path)\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n    cap.release()\n\n    ### tracker config\n    byte_tracker = sv.ByteTrack(\n        track_activation_threshold=track_activation_threshold,\n        lost_track_buffer=track_seconds * fps,\n        minimum_matching_threshold=minimum_matching_threshold,\n        frame_rate=fps,\n    )\n\n    ### video config\n    video_info = sv.VideoInfo.from_video_path(video_path=source_video_path)\n    frames_generator = sv.get_video_frames_generator(\n        source_path=source_video_path, stride=1\n    )\n\n    ### Detect, track, annotate, save\n    with sv.VideoSink(target_path=target_video_path, video_info=video_info) as sink:\n        for frame in frames_generator:\n            result = model(\n                source=frame,\n                classes=[0],  # only person class\n                conf=confidence_threshold,\n                iou=iou_threshold,\n                # show_conf = True,\n                # save_txt = True,\n                # save_conf = True,\n                # save = True,\n                device=None,  # use None = CPU, 0 = single GPU, or [0,1] = dual GPU\n            )[0]\n\n            detections = sv.Detections.from_ultralytics(result)  # get detections\n\n            detections = byte_tracker.update_with_detections(\n                detections\n            )  # update tracker\n\n            ### draw heatmap\n            annotated_frame = heat_map_annotator.annotate(\n                scene=frame.copy(), detections=detections\n            )\n\n            ### draw other attributes from `detections` object\n            labels = [\n                f\"#{tracker_id}\"\n                for class_id, tracker_id in zip(\n                    detections.class_id, detections.tracker_id\n                )\n            ]\n\n            label_annotator.annotate(\n                scene=annotated_frame, detections=detections, labels=labels\n            )\n\n            sink.write_frame(frame=annotated_frame)",
    "source": "github_repo:roboflow/supervision",
    "file": "examples/heatmap_and_track/script.py",
    "license": "MIT",
    "language": "python"
}